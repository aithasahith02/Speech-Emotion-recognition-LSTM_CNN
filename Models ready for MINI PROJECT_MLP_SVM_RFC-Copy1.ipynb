{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eec9db7",
   "metadata": {},
   "source": [
    "# Importing Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c30e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import soundfile\n",
    "import os\n",
    "import sys\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from IPython.display import Audio\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42609f9c",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd4dfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>C:/Users/hp/Downloads/Speech-Emotion-Recogniza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>C:/Users/hp/Downloads/Speech-Emotion-Recogniza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>C:/Users/hp/Downloads/Speech-Emotion-Recogniza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>C:/Users/hp/Downloads/Speech-Emotion-Recogniza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calm</td>\n",
       "      <td>C:/Users/hp/Downloads/Speech-Emotion-Recogniza...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                              Paths\n",
       "0  neutral  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
       "1  neutral  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
       "2  neutral  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
       "3  neutral  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
       "4     calm  C:/Users/hp/Downloads/Speech-Emotion-Recogniza..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset from the \"dataset folder and mapping them to obtain a pandas dataframe\"\n",
    "dataset_path = \"C:/Users/hp/Downloads/Speech-Emotion-Recognization-master/Speech-Emotion-Recognization-master/dataset/\"\n",
    "dataDirectorylist = os.listdir(dataset_path)\n",
    "Emotion=[]\n",
    "path=[]\n",
    "for dir in dataDirectorylist:\n",
    "    actor = os.listdir(dataset_path+dir)\n",
    "    for file in actor :\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        Emotion.append(int(part[2]))\n",
    "        path.append(dataset_path+dir+'//'+file)\n",
    "emotion_df = pd.DataFrame(Emotion,columns=['Emotions'])\n",
    "emotion_df = emotion_df.Emotions.replace({1:'neutral',2: 'calm',3: 'happy',4: 'sad',5: 'angry',6: 'fearful',7: 'disgust',8: 'surprised'})\n",
    "\n",
    "path_df = pd.DataFrame(path,columns=['Paths'])\n",
    "dataset_dataframe = pd.concat([emotion_df,path_df],axis=1)\n",
    "\n",
    "dataset_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd5f6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Emotions                                              Paths\n",
      "0       neutral  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "1       neutral  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "2       neutral  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "3       neutral  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "4          calm  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "...         ...                                                ...\n",
      "1435  surprised  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "1436  surprised  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "1437  surprised  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "1438  surprised  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "1439  surprised  C:/Users/hp/Downloads/Speech-Emotion-Recogniza...\n",
      "\n",
      "[1440 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#converting the data into a CSV file\n",
    "dataset_dataframe = pd.concat([dataset_dataframe],axis=0)\n",
    "dataset_dataframe.to_csv(\"data_path.csv\",index=False)\n",
    "dataset_dataframe.head\n",
    "dataPath=pd.read_csv(\"data_path.csv\")\n",
    "print(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459bc4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Analysis on the data with the file and graphs\n",
    "plt.title(\"Counting Emotions\")\n",
    "sn.countplot(dataPath.Emotions)\n",
    "plt.xlabel('Emotions')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca76ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveplot(data,sr,e) :\n",
    "    plt.figure(figsize=(10,3))\n",
    "    librosa.display.waveshow(data,sr=sr,label=e)\n",
    "    plt.title(e)\n",
    "    plt.show()\n",
    "    Audio(path)\n",
    "    song = AudioSegment.from_wav(path)\n",
    "    print('playing the emotion :',e)\n",
    "    play(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c057c",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4ae5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION :  neutral\n",
      "Chroma Visualization for the emotion:  neutral\n",
      "Spectogram for the emotion  neutral\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'QuadMesh' object has no property 'x_axzis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m Xdb \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mamplitude_to_db(\u001b[38;5;28mabs\u001b[39m(X))\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_axzis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZero Crossing rate for the emotion \u001b[39m\u001b[38;5;124m\"\u001b[39m,emotion)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\display.py:879\u001b[0m, in \u001b[0;36mspecshow\u001b[1;34m(data, x_coords, y_coords, x_axis, y_axis, sr, hop_length, n_fft, win_length, fmin, fmax, tuning, bins_per_octave, key, Sa, mela, thaat, auto_aspect, htk, unicode, ax, **kwargs)\u001b[0m\n\u001b[0;32m    875\u001b[0m x_coords \u001b[38;5;241m=\u001b[39m __mesh_coords(x_axis, x_coords, data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_params)\n\u001b[0;32m    877\u001b[0m axes \u001b[38;5;241m=\u001b[39m __check_axes(ax)\n\u001b[1;32m--> 879\u001b[0m out \u001b[38;5;241m=\u001b[39m axes\u001b[38;5;241m.\u001b[39mpcolormesh(x_coords, y_coords, data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    881\u001b[0m __set_current_image(ax, out)\n\u001b[0;32m    883\u001b[0m \u001b[38;5;66;03m# Set up axis scaling\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6070\u001b[0m, in \u001b[0;36mAxes.pcolormesh\u001b[1;34m(self, alpha, norm, cmap, vmin, vmax, shading, antialiased, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6066\u001b[0m C \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m   6068\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnap\u001b[39m\u001b[38;5;124m'\u001b[39m, rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcolormesh.snap\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 6070\u001b[0m collection \u001b[38;5;241m=\u001b[39m mcoll\u001b[38;5;241m.\u001b[39mQuadMesh(\n\u001b[0;32m   6071\u001b[0m     coords, antialiased\u001b[38;5;241m=\u001b[39mantialiased, shading\u001b[38;5;241m=\u001b[39mshading,\n\u001b[0;32m   6072\u001b[0m     array\u001b[38;5;241m=\u001b[39mC, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, alpha\u001b[38;5;241m=\u001b[39malpha, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   6073\u001b[0m collection\u001b[38;5;241m.\u001b[39m_scale_norm(norm, vmin, vmax)\n\u001b[0;32m   6074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pcolor_grid_deprecation_helper()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\collections.py:2016\u001b[0m, in \u001b[0;36mQuadMesh.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2013\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bbox\u001b[38;5;241m.\u001b[39mupdate_from_data_xy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinates\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m   2014\u001b[0m \u001b[38;5;66;03m# super init delayed after own init because array kwarg requires\u001b[39;00m\n\u001b[0;32m   2015\u001b[0m \u001b[38;5;66;03m# self._coordinates and self._shading\u001b[39;00m\n\u001b[1;32m-> 2016\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\collections.py:221\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, transOffset, norm, cmap, pickradius, hatch, urls, zorder, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transOffset \u001b[38;5;241m=\u001b[39m transOffset\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_effects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py:1064\u001b[0m, in \u001b[0;36mArtist.update\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1062\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(func):\n\u001b[1;32m-> 1064\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1065\u001b[0m                                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no property \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1066\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'QuadMesh' object has no property 'x_axzis'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_list=['neutral','calm','happy','sad','angry','fearful','disgust','surprised']\n",
    "for emotion in emotions_list :\n",
    "    print(\"EMOTION : \",emotion)\n",
    "    print(\"Chroma Visualization for the emotion: \",emotion)\n",
    "    print(\"Spectogram for the emotion \",emotion)\n",
    "    df=dataPath\n",
    "    \n",
    "    path=np.array(df.Paths[df.Emotions==emotion])[4]\n",
    "    \n",
    "    x, sr = librosa.load(path)\n",
    "    X = librosa.stft(x)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axzis='time', y_axis='hz')\n",
    "    plt.colorbar()\n",
    "    print(\"Zero Crossing rate for the emotion \",emotion)\n",
    "    y, sr = librosa.load(path)\n",
    "    zcrs = librosa.feature.zero_crossing_rate(y)\n",
    "    print(f\"Zero crossing rate: {sum(librosa.zero_crossings(y))}\")\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.plot(zcrs[0])\n",
    "    plt.title(emotion)\n",
    "    data,samplingrate=librosa.load(path)\n",
    "    waveplot(data,samplingrate,emotion)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cdf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data) :\n",
    "    noiseAmp=0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data+noiseAmp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "def stretch(data,rate=0.8) :\n",
    "    return librosa.effects.time_stretch(data,rate)\n",
    "def shift(data) :\n",
    "    shiftrange=int(np.random.uniform(low=-5,high=5)*1000)\n",
    "    return np.roll(data,shiftrange)\n",
    "def pitch(data,samplingRate,pitchFactor=0.7) :\n",
    "    return librosa.effects.pitch_shift(data,samplingRate,pitchFactor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=noise(data)\n",
    "plt.figure(figsize=(14,2))\n",
    "librosa.display.waveshow(y=x,sr=samplingrate)\n",
    "song = AudioSegment.from_wav(path)\n",
    "print(\"Playing.......\")\n",
    "play(song)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf24123",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=stretch(data)\n",
    "plt.figure(figsize=(14,2))\n",
    "librosa.display.waveshow(y=x,sr=samplingrate)\n",
    "song = AudioSegment.from_wav(path)\n",
    "print(\"Playing.......\")\n",
    "play(song)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=shift(data)\n",
    "plt.figure(figsize=(14,2))\n",
    "librosa.display.waveshow(y=x,sr=samplingrate)\n",
    "song = AudioSegment.from_wav(path)\n",
    "print(\"Playing.......\")\n",
    "play(song)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef406e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pitch(data,samplingrate)\n",
    "plt.figure(figsize=(14,2))\n",
    "librosa.display.waveshow(y=x,sr=samplingrate)\n",
    "song = AudioSegment.from_wav(path)\n",
    "print(\"Playing.......\")\n",
    "play(song)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6398143",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:d\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05001b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ec312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"dataset//Actor_*//*.wav\"):\n",
    "        print(file,end=\"\")\n",
    "        filename=os.path.basename(file)\n",
    "        emotion=emotions[(filename.split(\"-\")[2])]\n",
    "        print(\"\",emotion)\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples:\", x_train.shape[0])\n",
    "print(\" Number of testing samples:\", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0e982",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "myclassifier=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "myclassifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_y=y_test\n",
    "actual_y=myclassifier.predict(x_test)\n",
    "print(metrics.confusion_matrix(expected_y,actual_y))\n",
    "print(accuracy_score(y_true=y_test,y_pred=dtree_predictions))\n",
    "print(classification_report(expected_y,actual_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d414095",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(expected_y,actual_y)\n",
    "cm_df = pd.DataFrame(cm,index = ['Angry','Calm','Disgust','Fearful','Happy','Neutral','Sad','Surprised'], columns = ['Angry','Calm','Disgust','Fearful','Happy','Neutral','Sad','Surprised'])\n",
    "plt.figure(figsize=(5,4))\n",
    "sn.heatmap(cm_df,annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff70dd6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be51a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth = 6).fit(x_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(x_test) \n",
    "print(accuracy_score(y_true=y_test,y_pred=dtree_predictions))\n",
    "print(classification_report(y_test,dtree_predictions)) \n",
    "print(confusion_matrix(y_test, dtree_predictions) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322795d",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(x_test) \n",
    "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
    "print(classification_report(y_test,svm_predictions)) \n",
    "print(confusion_matrix(y_test, svm_predictions) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60418bc",
   "metadata": {},
   "source": [
    "# Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 100, random_state = 0) \n",
    "classifier.fit(x_train, y_train)   \n",
    "c_p = classifier.predict(x_test) \n",
    "print(accuracy_score(y_true=y_test,y_pred=c_p))\n",
    "print(classification_report(y_test,c_p)) \n",
    "print(confusion_matrix(y_test,c_p) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
