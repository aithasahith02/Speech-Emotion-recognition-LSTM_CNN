{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rSku0_cX3dB"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWJ9phRhUDrM"
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI3q89z5YLVq"
   },
   "outputs": [],
   "source": [
    "def load_data(train_size=0.8,test_size=0.2):\n",
    "    X, y = [], []\n",
    "    try :\n",
    "        for file in glob.glob(\"C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset/Actor_*/*.wav\"):\n",
    "            # get the base name of the audio file\n",
    "            print(file)\n",
    "            basename = os.path.basename(file)\n",
    "            print(basename)\n",
    "          # get the emotion label\n",
    "            emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "          # we allow only AVAILABLE_EMOTIONS we set\n",
    "            if emotion not in AVAILABLE_EMOTIONS:\n",
    "                continue\n",
    "          # extract speech features\n",
    "            features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "          # add to data\n",
    "            X.append(features)\n",
    "            l={'happy':0.0,'sad':1.0,'neutral':3.0,'angry':4.0}\n",
    "            y.append(l[emotion])\n",
    "    except :\n",
    "         pass\n",
    "    # split the data to training and testing and return it\n",
    "    return train_test_split(np.array(X), y, test_size=test_size,train_size=train_size,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"neutral\",\n",
    "    \"happy\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p7USodbIYQli",
    "outputId": "7fd11920-7a3e-405e-a828-3f7d50aa97ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-01-01-01.wav\n",
      "03-01-01-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-01-02-01.wav\n",
      "03-01-01-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-02-01-01.wav\n",
      "03-01-01-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-02-02-01.wav\n",
      "03-01-01-01-02-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-01-01-01.wav\n",
      "03-01-02-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-01-02-01.wav\n",
      "03-01-02-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-02-01-01.wav\n",
      "03-01-02-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-02-02-01.wav\n",
      "03-01-02-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-01-01-01.wav\n",
      "03-01-02-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-01-02-01.wav\n",
      "03-01-02-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-02-01-01.wav\n",
      "03-01-02-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-02-02-01.wav\n",
      "03-01-02-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-01-01-01.wav\n",
      "03-01-03-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-01-02-01.wav\n",
      "03-01-03-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-02-01-01.wav\n",
      "03-01-03-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-02-02-01.wav\n",
      "03-01-03-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-01-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-03-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-01-02-01.wav\n",
      "03-01-03-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-02-01-01.wav\n",
      "03-01-03-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-02-02-01.wav\n",
      "03-01-03-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-01-01-01.wav\n",
      "03-01-04-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-01-02-01.wav\n",
      "03-01-04-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-02-01-01.wav\n",
      "03-01-04-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-02-02-01.wav\n",
      "03-01-04-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-01-01-01.wav\n",
      "03-01-04-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-01-02-01.wav\n",
      "03-01-04-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-02-01-01.wav\n",
      "03-01-04-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-02-02-01.wav\n",
      "03-01-04-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-01-01-01.wav\n",
      "03-01-05-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-01-02-01.wav\n",
      "03-01-05-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-02-01-01.wav\n",
      "03-01-05-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-02-02-01.wav\n",
      "03-01-05-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-01-01-01.wav\n",
      "03-01-05-02-01-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00061035 -0.00048828 -0.00039673 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.00231934  0.00213623 -0.00231934 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-01-02-01.wav\n",
      "03-01-05-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-02-01-01.wav\n",
      "03-01-05-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-02-02-01.wav\n",
      "03-01-05-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-01-01-01.wav\n",
      "03-01-06-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-01-02-01.wav\n",
      "03-01-06-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-02-01-01.wav\n",
      "03-01-06-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-02-02-01.wav\n",
      "03-01-06-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-01-01-01.wav\n",
      "03-01-06-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-01-02-01.wav\n",
      "03-01-06-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-02-01-01.wav\n",
      "03-01-06-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-02-02-01.wav\n",
      "03-01-06-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-01-01-01.wav\n",
      "03-01-07-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-01-02-01.wav\n",
      "03-01-07-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-02-01-01.wav\n",
      "03-01-07-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-02-02-01.wav\n",
      "03-01-07-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-01-01-01.wav\n",
      "03-01-07-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-01-02-01.wav\n",
      "03-01-07-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-02-01-01.wav\n",
      "03-01-07-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-02-02-01.wav\n",
      "03-01-07-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-01-01-01.wav\n",
      "03-01-08-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-01-02-01.wav\n",
      "03-01-08-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-02-01-01.wav\n",
      "03-01-08-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-02-02-01.wav\n",
      "03-01-08-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-01-01-01.wav\n",
      "03-01-08-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-01-02-01.wav\n",
      "03-01-08-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-02-01-01.wav\n",
      "03-01-08-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-02-02-01.wav\n",
      "03-01-08-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-01-01-02.wav\n",
      "03-01-01-01-01-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 7.3242188e-04  1.0986328e-03 -6.7138672e-04 ...  9.1552734e-05\n",
      "  3.6621094e-04  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.00033569 0.00024414 0.00024414 ... 0.00036621 0.00033569 0.00045776] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-01-02-02.wav\n",
      "03-01-01-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-02-01-02.wav\n",
      "03-01-01-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-02-02-02.wav\n",
      "03-01-01-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-01-01-02.wav\n",
      "03-01-02-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-01-02-02.wav\n",
      "03-01-02-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-02-01-02.wav\n",
      "03-01-02-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-02-02-02.wav\n",
      "03-01-02-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-01-01-02.wav\n",
      "03-01-02-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-01-02-02.wav\n",
      "03-01-02-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-02-01-02.wav\n",
      "03-01-02-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-02-02-02.wav\n",
      "03-01-02-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-01-01-02.wav\n",
      "03-01-03-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-01-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-03-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-02-01-02.wav\n",
      "03-01-03-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-02-02-02.wav\n",
      "03-01-03-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-01-01-02.wav\n",
      "03-01-03-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-01-02-02.wav\n",
      "03-01-03-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-02-01-02.wav\n",
      "03-01-03-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-02-02-02.wav\n",
      "03-01-03-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-01-01-02.wav\n",
      "03-01-04-01-01-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-01-02-02.wav\n",
      "03-01-04-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-02-01-02.wav\n",
      "03-01-04-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-02-02-02.wav\n",
      "03-01-04-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-01-01-02.wav\n",
      "03-01-04-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-01-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-04-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-02-01-02.wav\n",
      "03-01-04-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-02-02-02.wav\n",
      "03-01-04-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-01-01-02.wav\n",
      "03-01-05-01-01-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-01-02-02.wav\n",
      "03-01-05-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-02-01-02.wav\n",
      "03-01-05-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-02-02-02.wav\n",
      "03-01-05-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-01-01-02.wav\n",
      "03-01-05-02-01-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-01-02-02.wav\n",
      "03-01-05-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-02-01-02.wav\n",
      "03-01-05-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-02-02-02.wav\n",
      "03-01-05-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-01-01-02.wav\n",
      "03-01-06-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-01-02-02.wav\n",
      "03-01-06-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-02-01-02.wav\n",
      "03-01-06-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-02-02-02.wav\n",
      "03-01-06-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-01-01-02.wav\n",
      "03-01-06-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-01-02-02.wav\n",
      "03-01-06-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-02-01-02.wav\n",
      "03-01-06-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-02-02-02.wav\n",
      "03-01-06-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-01-01-02.wav\n",
      "03-01-07-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-01-02-02.wav\n",
      "03-01-07-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-02-01-02.wav\n",
      "03-01-07-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-02-02-02.wav\n",
      "03-01-07-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-01-01-02.wav\n",
      "03-01-07-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-01-02-02.wav\n",
      "03-01-07-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-02-01-02.wav\n",
      "03-01-07-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-02-02-02.wav\n",
      "03-01-07-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-01-01-02.wav\n",
      "03-01-08-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-01-02-02.wav\n",
      "03-01-08-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-02-01-02.wav\n",
      "03-01-08-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-02-02-02.wav\n",
      "03-01-08-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-01-01-02.wav\n",
      "03-01-08-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-01-02-02.wav\n",
      "03-01-08-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-02-01-02.wav\n",
      "03-01-08-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-02-02-02.wav\n",
      "03-01-08-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-01-01-03.wav\n",
      "03-01-01-01-01-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  6.1035156e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-01-02-03.wav\n",
      "03-01-01-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-02-01-03.wav\n",
      "03-01-01-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-02-02-03.wav\n",
      "03-01-01-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-01-01-03.wav\n",
      "03-01-02-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-01-02-03.wav\n",
      "03-01-02-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-02-01-03.wav\n",
      "03-01-02-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-02-02-03.wav\n",
      "03-01-02-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-01-01-03.wav\n",
      "03-01-02-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-01-02-03.wav\n",
      "03-01-02-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-02-01-03.wav\n",
      "03-01-02-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-02-02-03.wav\n",
      "03-01-02-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-01-01-03.wav\n",
      "03-01-03-01-01-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  9.1552734e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 5.1879883e-04 -6.1035156e-05 -4.2724609e-04 ...  0.0000000e+00\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-01-02-03.wav\n",
      "03-01-03-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-02-01-03.wav\n",
      "03-01-03-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-02-02-03.wav\n",
      "03-01-03-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-01-01-03.wav\n",
      "03-01-03-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-01-02-03.wav\n",
      "03-01-03-02-01-02-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.5258789e-04 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00027466 -0.00024414 -0.00027466 ... -0.00015259 -0.00021362\n",
      " -0.00024414] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-04 -1.0986328e-03 ...  2.7465820e-04\n",
      "  3.0517578e-04  3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -1.5258789e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-02-01-03.wav\n",
      "03-01-03-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-02-02-03.wav\n",
      "03-01-03-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-01-01-03.wav\n",
      "03-01-04-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-01-02-03.wav\n",
      "03-01-04-01-01-02-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 6.1035156e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00042725 -0.00039673\n",
      " -0.00033569] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  2.7465820e-04\n",
      "  3.0517578e-04  2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.7138672e-04 -7.0190430e-04 -6.1035156e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-02-01-03.wav\n",
      "03-01-04-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-02-02-03.wav\n",
      "03-01-04-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-01-01-03.wav\n",
      "03-01-04-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-01-02-03.wav\n",
      "03-01-04-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-02-01-03.wav\n",
      "03-01-04-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-02-02-03.wav\n",
      "03-01-04-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-01-01-03.wav\n",
      "03-01-05-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-01-02-03.wav\n",
      "03-01-05-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-02-01-03.wav\n",
      "03-01-05-01-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  3.0517578e-05 ... -3.6926270e-03\n",
      " -7.4768066e-03 -8.6975098e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00247192 0.00247192 0.00244141] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  9.1552734e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -1.8310547e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  3.0517578e-05 ... -5.8593750e-03\n",
      " -5.8898926e-03 -6.0729980e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.8310547e-04  1.2207031e-04  3.0517578e-04 ... -1.8310547e-04\n",
      " -6.1035156e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.4086914e-04  2.7465820e-04 -6.1035156e-05 ... -1.7089844e-03\n",
      " -1.8615723e-03 -1.8005371e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-02-02-03.wav\n",
      "03-01-05-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-01-01-03.wav\n",
      "03-01-05-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-01-02-03.wav\n",
      "03-01-05-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-02-01-03.wav\n",
      "03-01-05-02-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 2.1362305e-04 3.3569336e-04 ... 0.0000000e+00 3.0517578e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 9.4604492e-04 7.0190430e-04\n",
      " 8.8500977e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-02-02-03.wav\n",
      "03-01-05-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-01-01-03.wav\n",
      "03-01-06-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-01-02-03.wav\n",
      "03-01-06-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-02-01-03.wav\n",
      "03-01-06-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-02-02-03.wav\n",
      "03-01-06-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-01-01-03.wav\n",
      "03-01-06-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-01-02-03.wav\n",
      "03-01-06-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-02-01-03.wav\n",
      "03-01-06-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-02-02-03.wav\n",
      "03-01-06-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-01-01-03.wav\n",
      "03-01-07-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-01-02-03.wav\n",
      "03-01-07-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-02-01-03.wav\n",
      "03-01-07-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-02-02-03.wav\n",
      "03-01-07-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-01-01-03.wav\n",
      "03-01-07-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-01-02-03.wav\n",
      "03-01-07-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-02-01-03.wav\n",
      "03-01-07-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-02-02-03.wav\n",
      "03-01-07-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-01-01-03.wav\n",
      "03-01-08-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-01-02-03.wav\n",
      "03-01-08-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-02-01-03.wav\n",
      "03-01-08-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-02-02-03.wav\n",
      "03-01-08-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-01-01-03.wav\n",
      "03-01-08-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-01-02-03.wav\n",
      "03-01-08-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-02-01-03.wav\n",
      "03-01-08-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-02-02-03.wav\n",
      "03-01-08-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-01-01-04.wav\n",
      "03-01-01-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-01-02-04.wav\n",
      "03-01-01-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-02-01-04.wav\n",
      "03-01-01-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-02-02-04.wav\n",
      "03-01-01-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-01-01-04.wav\n",
      "03-01-02-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-01-02-04.wav\n",
      "03-01-02-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-02-01-04.wav\n",
      "03-01-02-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-02-02-04.wav\n",
      "03-01-02-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-01-01-04.wav\n",
      "03-01-02-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-01-02-04.wav\n",
      "03-01-02-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-02-01-04.wav\n",
      "03-01-02-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-02-02-04.wav\n",
      "03-01-02-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-01-01-04.wav\n",
      "03-01-03-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-01-02-04.wav\n",
      "03-01-03-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-02-01-04.wav\n",
      "03-01-03-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-02-02-04.wav\n",
      "03-01-03-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-01-01-04.wav\n",
      "03-01-03-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-01-02-04.wav\n",
      "03-01-03-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-02-01-04.wav\n",
      "03-01-03-02-02-01-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-02-02-04.wav\n",
      "03-01-03-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-01-01-04.wav\n",
      "03-01-04-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-01-02-04.wav\n",
      "03-01-04-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-02-01-04.wav\n",
      "03-01-04-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-02-02-04.wav\n",
      "03-01-04-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-01-01-04.wav\n",
      "03-01-04-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-01-02-04.wav\n",
      "03-01-04-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-02-01-04.wav\n",
      "03-01-04-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-02-02-04.wav\n",
      "03-01-04-02-02-02-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -9.1552734e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 9.1552734e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-01-01-04.wav\n",
      "03-01-05-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-01-02-04.wav\n",
      "03-01-05-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-02-01-04.wav\n",
      "03-01-05-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-02-02-04.wav\n",
      "03-01-05-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-01-01-04.wav\n",
      "03-01-05-02-01-01-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-01-02-04.wav\n",
      "03-01-05-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-02-01-04.wav\n",
      "03-01-05-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-02-02-04.wav\n",
      "03-01-05-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-01-01-04.wav\n",
      "03-01-06-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-01-02-04.wav\n",
      "03-01-06-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-02-01-04.wav\n",
      "03-01-06-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-02-02-04.wav\n",
      "03-01-06-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-01-01-04.wav\n",
      "03-01-06-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-01-02-04.wav\n",
      "03-01-06-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-02-01-04.wav\n",
      "03-01-06-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-02-02-04.wav\n",
      "03-01-06-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-01-01-04.wav\n",
      "03-01-07-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-01-02-04.wav\n",
      "03-01-07-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-02-01-04.wav\n",
      "03-01-07-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-02-02-04.wav\n",
      "03-01-07-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-01-01-04.wav\n",
      "03-01-07-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-01-02-04.wav\n",
      "03-01-07-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-02-01-04.wav\n",
      "03-01-07-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-02-02-04.wav\n",
      "03-01-07-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-01-01-04.wav\n",
      "03-01-08-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-01-02-04.wav\n",
      "03-01-08-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-02-01-04.wav\n",
      "03-01-08-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-02-02-04.wav\n",
      "03-01-08-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-01-01-04.wav\n",
      "03-01-08-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-01-02-04.wav\n",
      "03-01-08-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-02-01-04.wav\n",
      "03-01-08-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-02-02-04.wav\n",
      "03-01-08-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-01-01-05.wav\n",
      "03-01-01-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-01-02-05.wav\n",
      "03-01-01-01-01-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -9.1552734e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05  6.1035156e-05 ... -9.1552734e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-02-01-05.wav\n",
      "03-01-01-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-02-02-05.wav\n",
      "03-01-01-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-01-01-05.wav\n",
      "03-01-02-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-01-02-05.wav\n",
      "03-01-02-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-02-01-05.wav\n",
      "03-01-02-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-02-02-05.wav\n",
      "03-01-02-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-01-01-05.wav\n",
      "03-01-02-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-01-02-05.wav\n",
      "03-01-02-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-02-01-05.wav\n",
      "03-01-02-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-02-02-05.wav\n",
      "03-01-02-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-01-01-05.wav\n",
      "03-01-03-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-01-02-05.wav\n",
      "03-01-03-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-02-01-05.wav\n",
      "03-01-03-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-02-02-05.wav\n",
      "03-01-03-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-01-01-05.wav\n",
      "03-01-03-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-01-02-05.wav\n",
      "03-01-03-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-02-01-05.wav\n",
      "03-01-03-02-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 6.1035156e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -1.5258789e-04 -1.5258789e-04 ...  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-02-02-05.wav\n",
      "03-01-03-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-01-01-05.wav\n",
      "03-01-04-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-01-02-05.wav\n",
      "03-01-04-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-02-01-05.wav\n",
      "03-01-04-01-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  6.1035156e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 3.0517578e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-02-02-05.wav\n",
      "03-01-04-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-01-01-05.wav\n",
      "03-01-04-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-01-02-05.wav\n",
      "03-01-04-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-02-01-05.wav\n",
      "03-01-04-02-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.00054932 0.00057983 0.00057983 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-02-02-05.wav\n",
      "03-01-04-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-01-01-05.wav\n",
      "03-01-05-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-01-02-05.wav\n",
      "03-01-05-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-02-01-05.wav\n",
      "03-01-05-01-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-02-02-05.wav\n",
      "03-01-05-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-01-01-05.wav\n",
      "03-01-05-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-01-02-05.wav\n",
      "03-01-05-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-02-01-05.wav\n",
      "03-01-05-02-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -9.1552734e-05 ...  4.2724609e-04\n",
      "  4.2724609e-04  4.2724609e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-02-02-05.wav\n",
      "03-01-05-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-01-01-05.wav\n",
      "03-01-06-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-01-02-05.wav\n",
      "03-01-06-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-02-01-05.wav\n",
      "03-01-06-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-02-02-05.wav\n",
      "03-01-06-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-01-01-05.wav\n",
      "03-01-06-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-01-02-05.wav\n",
      "03-01-06-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-02-01-05.wav\n",
      "03-01-06-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-02-02-05.wav\n",
      "03-01-06-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-01-01-05.wav\n",
      "03-01-07-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-01-02-05.wav\n",
      "03-01-07-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-02-01-05.wav\n",
      "03-01-07-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-02-02-05.wav\n",
      "03-01-07-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-01-01-05.wav\n",
      "03-01-07-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-01-02-05.wav\n",
      "03-01-07-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-02-01-05.wav\n",
      "03-01-07-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-02-02-05.wav\n",
      "03-01-07-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-01-01-05.wav\n",
      "03-01-08-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-01-02-05.wav\n",
      "03-01-08-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-02-01-05.wav\n",
      "03-01-08-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-02-02-05.wav\n",
      "03-01-08-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-01-01-05.wav\n",
      "03-01-08-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-01-02-05.wav\n",
      "03-01-08-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-02-01-05.wav\n",
      "03-01-08-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-02-02-05.wav\n",
      "03-01-08-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-01-01-06.wav\n",
      "03-01-01-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-01-02-06.wav\n",
      "03-01-01-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-02-01-06.wav\n",
      "03-01-01-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-02-02-06.wav\n",
      "03-01-01-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-01-01-06.wav\n",
      "03-01-02-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-01-02-06.wav\n",
      "03-01-02-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-02-01-06.wav\n",
      "03-01-02-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-02-02-06.wav\n",
      "03-01-02-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-01-01-06.wav\n",
      "03-01-02-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-01-02-06.wav\n",
      "03-01-02-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-02-01-06.wav\n",
      "03-01-02-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-02-02-06.wav\n",
      "03-01-02-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-01-01-06.wav\n",
      "03-01-03-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-01-02-06.wav\n",
      "03-01-03-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-02-01-06.wav\n",
      "03-01-03-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-02-02-06.wav\n",
      "03-01-03-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-01-01-06.wav\n",
      "03-01-03-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-01-02-06.wav\n",
      "03-01-03-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-02-01-06.wav\n",
      "03-01-03-02-02-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  3.0517578e-05\n",
      " -3.0517578e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-02-02-06.wav\n",
      "03-01-03-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-01-01-06.wav\n",
      "03-01-04-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-01-02-06.wav\n",
      "03-01-04-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-02-01-06.wav\n",
      "03-01-04-01-02-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 6.1035156e-04 6.1035156e-04\n",
      " 5.7983398e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-02-02-06.wav\n",
      "03-01-04-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-01-01-06.wav\n",
      "03-01-04-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-01-02-06.wav\n",
      "03-01-04-02-01-02-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.00024414 0.00021362 0.00021362 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-02-01-06.wav\n",
      "03-01-04-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-02-02-06.wav\n",
      "03-01-04-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-01-01-06.wav\n",
      "03-01-05-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-01-02-06.wav\n",
      "03-01-05-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-02-01-06.wav\n",
      "03-01-05-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-02-02-06.wav\n",
      "03-01-05-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-01-01-06.wav\n",
      "03-01-05-02-01-01-06.wav"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00015259 0.00015259 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-01-02-06.wav\n",
      "03-01-05-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-02-01-06.wav\n",
      "03-01-05-02-02-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 8.2397461e-04  5.1879883e-04  3.0517578e-04 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05 -3.0517578e-05 -4.8828125e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  9.1552734e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-02-02-06.wav\n",
      "03-01-05-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-01-01-06.wav\n",
      "03-01-06-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-01-02-06.wav\n",
      "03-01-06-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-02-01-06.wav\n",
      "03-01-06-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-02-02-06.wav\n",
      "03-01-06-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-01-01-06.wav\n",
      "03-01-06-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-01-02-06.wav\n",
      "03-01-06-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-02-01-06.wav\n",
      "03-01-06-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-02-02-06.wav\n",
      "03-01-06-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-01-01-06.wav\n",
      "03-01-07-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-01-02-06.wav\n",
      "03-01-07-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-02-01-06.wav\n",
      "03-01-07-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-02-02-06.wav\n",
      "03-01-07-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-01-01-06.wav\n",
      "03-01-07-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-01-02-06.wav\n",
      "03-01-07-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-02-01-06.wav\n",
      "03-01-07-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-02-02-06.wav\n",
      "03-01-07-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-01-01-06.wav\n",
      "03-01-08-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-01-02-06.wav\n",
      "03-01-08-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-02-01-06.wav\n",
      "03-01-08-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-02-02-06.wav\n",
      "03-01-08-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-01-01-06.wav\n",
      "03-01-08-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-01-02-06.wav\n",
      "03-01-08-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-02-01-06.wav\n",
      "03-01-08-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-02-02-06.wav\n",
      "03-01-08-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-01-01-07.wav\n",
      "03-01-01-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-01-02-07.wav\n",
      "03-01-01-01-01-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-2.1362305e-04 -1.8310547e-04  6.1035156e-05 ... -1.5258789e-04\n",
      " -1.8310547e-04 -2.4414062e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -1.2207031e-04  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-02-01-07.wav\n",
      "03-01-01-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-02-02-07.wav\n",
      "03-01-01-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-01-01-07.wav\n",
      "03-01-02-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-01-02-07.wav\n",
      "03-01-02-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-02-01-07.wav\n",
      "03-01-02-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-02-02-07.wav\n",
      "03-01-02-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-01-01-07.wav\n",
      "03-01-02-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-01-02-07.wav\n",
      "03-01-02-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-02-01-07.wav\n",
      "03-01-02-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-02-02-07.wav\n",
      "03-01-02-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-01-01-07.wav\n",
      "03-01-03-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-01-02-07.wav\n",
      "03-01-03-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-02-01-07.wav\n",
      "03-01-03-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-02-02-07.wav\n",
      "03-01-03-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-01-01-07.wav\n",
      "03-01-03-02-01-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05  0.0000000e+00  3.0517578e-05 ...  2.7465820e-04\n",
      "  2.4414062e-04  2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  6.1035156e-05\n",
      "  9.1552734e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 2.1362305e-04  7.9345703e-04 -1.2207031e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-01-02-07.wav\n",
      "03-01-03-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-02-01-07.wav\n",
      "03-01-03-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-02-02-07.wav\n",
      "03-01-03-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-01-01-07.wav\n",
      "03-01-04-01-01-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05 -6.1035156e-05 ... -3.3569336e-04\n",
      " -3.9672852e-04 -4.2724609e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  4.2724609e-04  6.4086914e-04 ...  1.2207031e-04\n",
      "  9.1552734e-05  1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-01-02-07.wav\n",
      "03-01-04-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-02-01-07.wav\n",
      "03-01-04-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-02-02-07.wav\n",
      "03-01-04-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-01-01-07.wav\n",
      "03-01-04-02-01-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -2.4414062e-04 -3.9672852e-04 ...  3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  3.0517578e-05 ...  1.0681152e-03\n",
      "  1.0681152e-03  1.0681152e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.00042725  0.00033569  0.00033569 ... -0.00402832 -0.00390625\n",
      " -0.00390625] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-01-02-07.wav\n",
      "03-01-04-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-02-01-07.wav\n",
      "03-01-04-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-02-02-07.wav\n",
      "03-01-04-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-01-01-07.wav\n",
      "03-01-05-01-01-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -8.2397461e-04\n",
      " -8.2397461e-04 -8.2397461e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  9.1552734e-05  1.2207031e-04 ... -2.1057129e-03\n",
      " -2.1362305e-03 -2.1362305e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-01-02-07.wav\n",
      "03-01-05-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-02-01-07.wav\n",
      "03-01-05-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-02-02-07.wav\n",
      "03-01-05-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-01-01-07.wav\n",
      "03-01-05-02-01-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00064087 -0.00057983 -0.00054932 ...  0.00231934  0.00228882\n",
      "  0.00228882] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.00012207  0.00015259  0.00012207 ... -0.00204468 -0.00201416\n",
      " -0.00204468] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -1.8310547e-04 ...  3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -3.3569336e-04\n",
      " -3.3569336e-04 -3.3569336e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-01-02-07.wav\n",
      "03-01-05-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-02-01-07.wav\n",
      "03-01-05-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-02-02-07.wav\n",
      "03-01-05-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-01-01-07.wav\n",
      "03-01-06-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-01-02-07.wav\n",
      "03-01-06-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-02-01-07.wav\n",
      "03-01-06-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-02-02-07.wav\n",
      "03-01-06-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-01-01-07.wav\n",
      "03-01-06-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-01-02-07.wav\n",
      "03-01-06-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-02-01-07.wav\n",
      "03-01-06-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-02-02-07.wav\n",
      "03-01-06-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-01-01-07.wav\n",
      "03-01-07-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-01-02-07.wav\n",
      "03-01-07-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-02-01-07.wav\n",
      "03-01-07-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-02-02-07.wav\n",
      "03-01-07-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-01-01-07.wav\n",
      "03-01-07-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-01-02-07.wav\n",
      "03-01-07-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-02-01-07.wav\n",
      "03-01-07-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-02-02-07.wav\n",
      "03-01-07-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-01-01-07.wav\n",
      "03-01-08-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-01-02-07.wav\n",
      "03-01-08-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-02-01-07.wav\n",
      "03-01-08-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-02-02-07.wav\n",
      "03-01-08-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-01-01-07.wav\n",
      "03-01-08-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-01-02-07.wav\n",
      "03-01-08-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-02-01-07.wav\n",
      "03-01-08-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-02-02-07.wav\n",
      "03-01-08-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-01-01-08.wav\n",
      "03-01-01-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-01-02-08.wav\n",
      "03-01-01-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-02-01-08.wav\n",
      "03-01-01-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-02-02-08.wav\n",
      "03-01-01-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00015259 -0.00015259 -0.00015259 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 9.1552734e-05 1.2207031e-04 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.00018311 0.00018311 0.00021362 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-01-01-08.wav\n",
      "03-01-02-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-01-02-08.wav\n",
      "03-01-02-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-02-01-08.wav\n",
      "03-01-02-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-02-02-08.wav\n",
      "03-01-02-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-01-01-08.wav\n",
      "03-01-02-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-01-02-08.wav\n",
      "03-01-02-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-02-01-08.wav\n",
      "03-01-02-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-02-02-08.wav\n",
      "03-01-02-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-01-01-08.wav\n",
      "03-01-03-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-01-02-08.wav\n",
      "03-01-03-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-02-01-08.wav\n",
      "03-01-03-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-02-02-08.wav\n",
      "03-01-03-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 6.1035156e-05 ... 9.1552734e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  3.0517578e-05 ... -1.5258789e-04\n",
      " -1.2207031e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-01-01-08.wav\n",
      "03-01-03-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-01-02-08.wav\n",
      "03-01-03-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-02-01-08.wav\n",
      "03-01-03-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-02-02-08.wav\n",
      "03-01-03-02-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -6.1035156e-05 -6.1035156e-05 ...  6.1035156e-05\n",
      "  3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -3.6621094e-04\n",
      " -3.6621094e-04 -3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05 -6.1035156e-05 ... -2.7465820e-04\n",
      " -2.1362305e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-01-01-08.wav\n",
      "03-01-04-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-01-02-08.wav\n",
      "03-01-04-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-02-01-08.wav\n",
      "03-01-04-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-02-02-08.wav\n",
      "03-01-04-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[2.4414062e-04 2.4414062e-04 2.4414062e-04 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.00012207 0.00015259 0.00015259 ... 0.00015259 0.00018311 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-01-01-08.wav\n",
      "03-01-04-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-01-02-08.wav\n",
      "03-01-04-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-02-01-08.wav\n",
      "03-01-04-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-02-02-08.wav\n",
      "03-01-04-02-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 1.8310547e-04  2.1362305e-04  2.1362305e-04 ... -1.2207031e-04\n",
      "  0.0000000e+00 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00088501 0.00076294 0.00076294] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00231934 0.00238037 0.00234985] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-01-01-08.wav\n",
      "03-01-05-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-01-02-08.wav\n",
      "03-01-05-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-02-01-08.wav\n",
      "03-01-05-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-02-02-08.wav\n",
      "03-01-05-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ... -8.5449219e-04\n",
      " -6.4086914e-04  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ... -2.4414062e-04\n",
      " -2.1667480e-03 -2.4414062e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  6.1035156e-05  1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00018311 -0.00018311 -0.00018311 ...  0.00027466  0.00027466\n",
      "  0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-01-01-08.wav\n",
      "03-01-05-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-01-02-08.wav\n",
      "03-01-05-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-02-01-08.wav\n",
      "03-01-05-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-02-02-08.wav\n",
      "03-01-05-02-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.00018311  0.00015259  0.00018311 ... -0.00021362 -0.00018311\n",
      " -0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.00012207 0.00012207 0.00012207 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.8310547e-04 1.8310547e-04 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-01-01-08.wav\n",
      "03-01-06-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-01-02-08.wav\n",
      "03-01-06-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-02-01-08.wav\n",
      "03-01-06-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-02-02-08.wav\n",
      "03-01-06-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-01-01-08.wav\n",
      "03-01-06-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-01-02-08.wav\n",
      "03-01-06-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-02-01-08.wav\n",
      "03-01-06-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-02-02-08.wav\n",
      "03-01-06-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-01-01-08.wav\n",
      "03-01-07-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-01-02-08.wav\n",
      "03-01-07-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-02-01-08.wav\n",
      "03-01-07-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-02-02-08.wav\n",
      "03-01-07-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-01-01-08.wav\n",
      "03-01-07-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-01-02-08.wav\n",
      "03-01-07-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-02-01-08.wav\n",
      "03-01-07-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-02-02-08.wav\n",
      "03-01-07-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-01-01-08.wav\n",
      "03-01-08-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-01-02-08.wav\n",
      "03-01-08-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-02-01-08.wav\n",
      "03-01-08-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-02-02-08.wav\n",
      "03-01-08-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-01-01-08.wav\n",
      "03-01-08-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-01-02-08.wav\n",
      "03-01-08-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-02-01-08.wav\n",
      "03-01-08-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-02-02-08.wav\n",
      "03-01-08-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-01-01-09.wav\n",
      "03-01-01-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-01-02-09.wav\n",
      "03-01-01-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-02-01-09.wav\n",
      "03-01-01-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-02-02-09.wav\n",
      "03-01-01-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 8.5449219e-04  8.5449219e-04  8.8500977e-04 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-01-01-09.wav\n",
      "03-01-02-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-01-02-09.wav\n",
      "03-01-02-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-02-01-09.wav\n",
      "03-01-02-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-02-02-09.wav\n",
      "03-01-02-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-01-01-09.wav\n",
      "03-01-02-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-01-02-09.wav\n",
      "03-01-02-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-02-01-09.wav\n",
      "03-01-02-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-02-02-09.wav\n",
      "03-01-02-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-01-01-09.wav\n",
      "03-01-03-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-01-02-09.wav\n",
      "03-01-03-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-02-01-09.wav\n",
      "03-01-03-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-02-02-09.wav\n",
      "03-01-03-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0007019  0.00067139 0.00067139 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-01-01-09.wav\n",
      "03-01-03-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-01-02-09.wav\n",
      "03-01-03-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-02-01-09.wav\n",
      "03-01-03-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-02-02-09.wav\n",
      "03-01-03-02-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -1.2207031e-04\n",
      " -1.2207031e-04 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05  3.0517578e-05  3.0517578e-05 ...  6.1035156e-05\n",
      " -3.0517578e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-01-01-09.wav\n",
      "03-01-04-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-01-02-09.wav\n",
      "03-01-04-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-02-01-09.wav\n",
      "03-01-04-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-02-02-09.wav\n",
      "03-01-04-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-01-01-09.wav\n",
      "03-01-04-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-01-02-09.wav\n",
      "03-01-04-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-02-01-09.wav\n",
      "03-01-04-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-02-02-09.wav\n",
      "03-01-04-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-01-01-09.wav\n",
      "03-01-05-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-01-02-09.wav\n",
      "03-01-05-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-02-01-09.wav\n",
      "03-01-05-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-02-02-09.wav\n",
      "03-01-05-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00012207 -0.00012207\n",
      " -0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  0.0000000e+00 ... -2.7465820e-04\n",
      " -3.0517578e-04 -2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -1.5258789e-04\n",
      " -1.2207031e-04 -2.1362305e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 1.2207031e-04 1.8310547e-04 ... 1.5258789e-04 1.8310547e-04\n",
      " 1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-01-01-09.wav\n",
      "03-01-05-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-01-02-09.wav\n",
      "03-01-05-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-02-01-09.wav\n",
      "03-01-05-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-02-02-09.wav\n",
      "03-01-05-02-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.00027466  0.00048828  0.0005188  ... -0.00036621 -0.00042725\n",
      " -0.00033569] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 3.0517578e-05 6.1035156e-05 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  2.7465820e-04 ...  6.1035156e-05\n",
      "  9.1552734e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-01-01-09.wav\n",
      "03-01-06-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-01-02-09.wav\n",
      "03-01-06-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-02-01-09.wav\n",
      "03-01-06-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-02-02-09.wav\n",
      "03-01-06-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-01-01-09.wav\n",
      "03-01-06-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-01-02-09.wav\n",
      "03-01-06-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-02-01-09.wav\n",
      "03-01-06-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-02-02-09.wav\n",
      "03-01-06-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-01-01-09.wav\n",
      "03-01-07-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-01-02-09.wav\n",
      "03-01-07-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-02-01-09.wav\n",
      "03-01-07-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-02-02-09.wav\n",
      "03-01-07-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-01-01-09.wav\n",
      "03-01-07-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-01-02-09.wav\n",
      "03-01-07-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-02-01-09.wav\n",
      "03-01-07-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-02-02-09.wav\n",
      "03-01-07-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-01-01-09.wav\n",
      "03-01-08-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-01-02-09.wav\n",
      "03-01-08-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-02-01-09.wav\n",
      "03-01-08-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-02-02-09.wav\n",
      "03-01-08-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-01-01-09.wav\n",
      "03-01-08-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-01-02-09.wav\n",
      "03-01-08-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-02-01-09.wav\n",
      "03-01-08-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-02-02-09.wav\n",
      "03-01-08-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-01-01-10.wav\n",
      "03-01-01-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-01-02-10.wav\n",
      "03-01-01-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-02-01-10.wav\n",
      "03-01-01-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-02-02-10.wav\n",
      "03-01-01-01-02-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  3.0517578e-05 ...  0.0000000e+00\n",
      " -9.1552734e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-01-01-10.wav\n",
      "03-01-02-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-01-02-10.wav\n",
      "03-01-02-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-02-01-10.wav\n",
      "03-01-02-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-02-02-10.wav\n",
      "03-01-02-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-01-01-10.wav\n",
      "03-01-02-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-01-02-10.wav\n",
      "03-01-02-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-02-01-10.wav\n",
      "03-01-02-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-02-02-10.wav\n",
      "03-01-02-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-01-01-10.wav\n",
      "03-01-03-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-01-02-10.wav\n",
      "03-01-03-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-02-01-10.wav\n",
      "03-01-03-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-02-02-10.wav\n",
      "03-01-03-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-01-01-10.wav\n",
      "03-01-03-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-01-02-10.wav\n",
      "03-01-03-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-02-01-10.wav\n",
      "03-01-03-02-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  3.0517578e-05 ...  3.9672852e-04\n",
      "  4.5776367e-04 -2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-2.7465820e-04  1.8310547e-04 -6.1035156e-05 ...  9.1552734e-05\n",
      "  1.2207031e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-02-02-10.wav\n",
      "03-01-03-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-01-01-10.wav\n",
      "03-01-04-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-01-02-10.wav\n",
      "03-01-04-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-02-01-10.wav\n",
      "03-01-04-01-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -1.2207031e-04\n",
      " -9.1552734e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 1.4648438e-03  6.1035156e-04  2.1667480e-03 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-02-02-10.wav\n",
      "03-01-04-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-01-01-10.wav\n",
      "03-01-04-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-01-02-10.wav\n",
      "03-01-04-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-02-01-10.wav\n",
      "03-01-04-02-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -1.2207031e-04 -9.1552734e-05 ...  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -6.1035156e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.9672852e-04  1.8310547e-04 -2.7465820e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -3.0517578e-05 -2.1362305e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04  6.1035156e-05  1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-02-02-10.wav\n",
      "03-01-04-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-01-01-10.wav\n",
      "03-01-05-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-01-02-10.wav\n",
      "03-01-05-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-02-01-10.wav\n",
      "03-01-05-01-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.4086914e-04  2.7465820e-04 -4.5776367e-04 ...  1.2207031e-04\n",
      "  9.1552734e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 1.5258789e-04 1.2207031e-04 ... 3.0517578e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-02-02-10.wav\n",
      "03-01-05-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-01-01-10.wav\n",
      "03-01-05-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-01-02-10.wav\n",
      "03-01-05-02-01-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[1.5258789e-04 1.5258789e-04 1.8310547e-04 ... 3.0517578e-05 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05  3.0517578e-05  6.1035156e-05 ... -3.0517578e-05\n",
      "  6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-02-01-10.wav\n",
      "03-01-05-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-02-02-10.wav\n",
      "03-01-05-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-01-01-10.wav\n",
      "03-01-06-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-01-02-10.wav\n",
      "03-01-06-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-02-01-10.wav\n",
      "03-01-06-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-02-02-10.wav\n",
      "03-01-06-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-01-01-10.wav\n",
      "03-01-06-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-01-02-10.wav\n",
      "03-01-06-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-02-01-10.wav\n",
      "03-01-06-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-02-02-10.wav\n",
      "03-01-06-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-01-01-10.wav\n",
      "03-01-07-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-01-02-10.wav\n",
      "03-01-07-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-02-01-10.wav\n",
      "03-01-07-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-02-02-10.wav\n",
      "03-01-07-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-01-01-10.wav\n",
      "03-01-07-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-01-02-10.wav\n",
      "03-01-07-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-02-01-10.wav\n",
      "03-01-07-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-02-02-10.wav\n",
      "03-01-07-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-01-01-10.wav\n",
      "03-01-08-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-01-02-10.wav\n",
      "03-01-08-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-02-01-10.wav\n",
      "03-01-08-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-02-02-10.wav\n",
      "03-01-08-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-01-01-10.wav\n",
      "03-01-08-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-01-02-10.wav\n",
      "03-01-08-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-02-01-10.wav\n",
      "03-01-08-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-02-02-10.wav\n",
      "03-01-08-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-01-01-11.wav\n",
      "03-01-01-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-01-02-11.wav\n",
      "03-01-01-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-02-01-11.wav\n",
      "03-01-01-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-02-02-11.wav\n",
      "03-01-01-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-01-01-11.wav\n",
      "03-01-02-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-01-02-11.wav\n",
      "03-01-02-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-02-01-11.wav\n",
      "03-01-02-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-02-02-11.wav\n",
      "03-01-02-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-01-01-11.wav\n",
      "03-01-02-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-01-02-11.wav\n",
      "03-01-02-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-02-01-11.wav\n",
      "03-01-02-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-02-02-11.wav\n",
      "03-01-02-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-01-01-11.wav\n",
      "03-01-03-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-01-02-11.wav\n",
      "03-01-03-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  4.5776367e-04\n",
      "  4.5776367e-04  4.5776367e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-05 -6.1035156e-05 ... -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-02-01-11.wav\n",
      "03-01-03-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-02-02-11.wav\n",
      "03-01-03-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-01-01-11.wav\n",
      "03-01-03-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-01-02-11.wav\n",
      "03-01-03-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 6.1035156e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  2.1362305e-04  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-02-01-11.wav\n",
      "03-01-03-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-02-02-11.wav\n",
      "03-01-03-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-01-01-11.wav\n",
      "03-01-04-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-01-02-11.wav\n",
      "03-01-04-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[1.2207031e-04 9.1552734e-05 9.1552734e-05 ... 1.8310547e-04 1.8310547e-04\n",
      " 1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 1.5258789e-04  1.2207031e-04  1.2207031e-04 ... -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-02-01-11.wav\n",
      "03-01-04-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-02-02-11.wav\n",
      "03-01-04-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-01-01-11.wav\n",
      "03-01-04-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-01-02-11.wav\n",
      "03-01-04-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -6.1035156e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ... -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-02-01-11.wav\n",
      "03-01-04-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-02-02-11.wav\n",
      "03-01-04-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-01-01-11.wav\n",
      "03-01-05-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-01-02-11.wav\n",
      "03-01-05-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 9.1552734e-05 9.1552734e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.5258789e-04 -1.5258789e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-02-01-11.wav\n",
      "03-01-05-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-02-02-11.wav\n",
      "03-01-05-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-01-01-11.wav\n",
      "03-01-05-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-01-02-11.wav\n",
      "03-01-05-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -6.1035156e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00027466 -0.00027466\n",
      " -0.00027466] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -9.1552734e-05 -6.1035156e-05 ... -1.2207031e-04\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-02-01-11.wav\n",
      "03-01-05-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-02-02-11.wav\n",
      "03-01-05-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-01-01-11.wav\n",
      "03-01-06-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-01-02-11.wav\n",
      "03-01-06-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-02-01-11.wav\n",
      "03-01-06-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-02-02-11.wav\n",
      "03-01-06-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-01-01-11.wav\n",
      "03-01-06-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-01-02-11.wav\n",
      "03-01-06-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-02-01-11.wav\n",
      "03-01-06-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-02-02-11.wav\n",
      "03-01-06-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-01-01-11.wav\n",
      "03-01-07-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-01-02-11.wav\n",
      "03-01-07-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-02-01-11.wav\n",
      "03-01-07-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-02-02-11.wav\n",
      "03-01-07-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-01-01-11.wav\n",
      "03-01-07-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-01-02-11.wav\n",
      "03-01-07-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-02-01-11.wav\n",
      "03-01-07-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-02-02-11.wav\n",
      "03-01-07-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-01-01-11.wav\n",
      "03-01-08-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-01-02-11.wav\n",
      "03-01-08-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-02-01-11.wav\n",
      "03-01-08-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-02-02-11.wav\n",
      "03-01-08-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-01-01-11.wav\n",
      "03-01-08-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-01-02-11.wav\n",
      "03-01-08-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-02-01-11.wav\n",
      "03-01-08-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-02-02-11.wav\n",
      "03-01-08-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-01-01-12.wav\n",
      "03-01-01-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-01-02-12.wav\n",
      "03-01-01-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-02-01-12.wav\n",
      "03-01-01-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-02-02-12.wav\n",
      "03-01-01-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-01-01-12.wav\n",
      "03-01-02-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-01-02-12.wav\n",
      "03-01-02-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-02-01-12.wav\n",
      "03-01-02-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-02-02-12.wav\n",
      "03-01-02-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-01-01-12.wav\n",
      "03-01-02-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-01-02-12.wav\n",
      "03-01-02-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-02-01-12.wav\n",
      "03-01-02-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-02-02-12.wav\n",
      "03-01-02-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-01-01-12.wav\n",
      "03-01-03-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-01-02-12.wav\n",
      "03-01-03-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-02-01-12.wav\n",
      "03-01-03-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-02-02-12.wav\n",
      "03-01-03-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-01-01-12.wav\n",
      "03-01-03-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-01-02-12.wav\n",
      "03-01-03-02-01-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00021362 -0.00024414\n",
      " -0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-02-01-12.wav\n",
      "03-01-03-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-02-02-12.wav\n",
      "03-01-03-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-01-01-12.wav\n",
      "03-01-04-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-01-02-12.wav\n",
      "03-01-04-01-01-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -3.0212402e-03\n",
      " -3.0212402e-03 -3.0212402e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[1.5258789e-04 1.5258789e-04 9.1552734e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-02-01-12.wav\n",
      "03-01-04-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-02-02-12.wav\n",
      "03-01-04-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-01-01-12.wav\n",
      "03-01-04-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-01-02-12.wav\n",
      "03-01-04-02-01-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.00033569 0.00033569 0.00033569 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.0015564  -0.0015564\n",
      " -0.00158691] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-02-01-12.wav\n",
      "03-01-04-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-02-02-12.wav\n",
      "03-01-04-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-01-01-12.wav\n",
      "03-01-05-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-01-02-12.wav\n",
      "03-01-05-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-02-01-12.wav\n",
      "03-01-05-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-02-02-12.wav\n",
      "03-01-05-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-01-01-12.wav\n",
      "03-01-05-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-01-02-12.wav\n",
      "03-01-05-02-01-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00152588 -0.00149536\n",
      " -0.00149536] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00283813 0.0027771  0.0027771 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-02-01-12.wav\n",
      "03-01-05-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-02-02-12.wav\n",
      "03-01-05-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-01-01-12.wav\n",
      "03-01-06-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-01-02-12.wav\n",
      "03-01-06-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-02-01-12.wav\n",
      "03-01-06-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-02-02-12.wav\n",
      "03-01-06-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-01-01-12.wav\n",
      "03-01-06-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-01-02-12.wav\n",
      "03-01-06-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-02-01-12.wav\n",
      "03-01-06-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-02-02-12.wav\n",
      "03-01-06-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-01-01-12.wav\n",
      "03-01-07-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-01-02-12.wav\n",
      "03-01-07-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-02-01-12.wav\n",
      "03-01-07-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-02-02-12.wav\n",
      "03-01-07-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-01-01-12.wav\n",
      "03-01-07-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-01-02-12.wav\n",
      "03-01-07-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-02-01-12.wav\n",
      "03-01-07-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-02-02-12.wav\n",
      "03-01-07-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-01-01-12.wav\n",
      "03-01-08-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-01-02-12.wav\n",
      "03-01-08-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-02-01-12.wav\n",
      "03-01-08-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-02-02-12.wav\n",
      "03-01-08-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-01-01-12.wav\n",
      "03-01-08-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-01-02-12.wav\n",
      "03-01-08-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-02-01-12.wav\n",
      "03-01-08-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-02-02-12.wav\n",
      "03-01-08-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-01-01-13.wav\n",
      "03-01-01-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-01-02-13.wav\n",
      "03-01-01-01-01-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00021362 -0.00027466\n",
      " -0.00024414] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-02-01-13.wav\n",
      "03-01-01-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-02-02-13.wav\n",
      "03-01-01-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-01-01-13.wav\n",
      "03-01-02-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-01-02-13.wav\n",
      "03-01-02-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-02-01-13.wav\n",
      "03-01-02-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-02-02-13.wav\n",
      "03-01-02-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-01-01-13.wav\n",
      "03-01-02-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-01-02-13.wav\n",
      "03-01-02-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-02-01-13.wav\n",
      "03-01-02-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-02-02-13.wav\n",
      "03-01-02-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-01-01-13.wav\n",
      "03-01-03-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-01-02-13.wav\n",
      "03-01-03-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-02-01-13.wav\n",
      "03-01-03-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-02-02-13.wav\n",
      "03-01-03-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-01-01-13.wav\n",
      "03-01-03-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-01-02-13.wav\n",
      "03-01-03-02-01-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05  3.0517578e-05 ... -6.1035156e-05\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-02-01-13.wav\n",
      "03-01-03-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-02-02-13.wav\n",
      "03-01-03-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-01-01-13.wav\n",
      "03-01-04-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-01-02-13.wav\n",
      "03-01-04-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-02-01-13.wav\n",
      "03-01-04-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-02-02-13.wav\n",
      "03-01-04-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-01-01-13.wav\n",
      "03-01-04-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-01-02-13.wav\n",
      "03-01-04-02-01-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-02-01-13.wav\n",
      "03-01-04-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-02-02-13.wav\n",
      "03-01-04-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-01-01-13.wav\n",
      "03-01-05-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-01-02-13.wav\n",
      "03-01-05-01-01-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-02-01-13.wav\n",
      "03-01-05-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-02-02-13.wav\n",
      "03-01-05-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-01-01-13.wav\n",
      "03-01-05-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-01-02-13.wav\n",
      "03-01-05-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-02-01-13.wav\n",
      "03-01-05-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-02-02-13.wav\n",
      "03-01-05-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-01-01-13.wav\n",
      "03-01-06-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-01-02-13.wav\n",
      "03-01-06-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-02-01-13.wav\n",
      "03-01-06-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-02-02-13.wav\n",
      "03-01-06-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-01-01-13.wav\n",
      "03-01-06-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-01-02-13.wav\n",
      "03-01-06-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-02-01-13.wav\n",
      "03-01-06-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-02-02-13.wav\n",
      "03-01-06-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-01-01-13.wav\n",
      "03-01-07-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-01-02-13.wav\n",
      "03-01-07-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-02-01-13.wav\n",
      "03-01-07-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-02-02-13.wav\n",
      "03-01-07-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-01-01-13.wav\n",
      "03-01-07-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-01-02-13.wav\n",
      "03-01-07-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-02-01-13.wav\n",
      "03-01-07-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-02-02-13.wav\n",
      "03-01-07-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-01-01-13.wav\n",
      "03-01-08-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-01-02-13.wav\n",
      "03-01-08-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-02-01-13.wav\n",
      "03-01-08-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-02-02-13.wav\n",
      "03-01-08-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-01-01-13.wav\n",
      "03-01-08-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-01-02-13.wav\n",
      "03-01-08-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-02-01-13.wav\n",
      "03-01-08-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-02-02-13.wav\n",
      "03-01-08-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-01-01-14.wav\n",
      "03-01-01-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-01-02-14.wav\n",
      "03-01-01-01-01-02-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -7.9345703e-04\n",
      " -8.2397461e-04 -8.2397461e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00012207 0.00012207 0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-02-01-14.wav\n",
      "03-01-01-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-02-02-14.wav\n",
      "03-01-01-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-01-01-14.wav\n",
      "03-01-02-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-01-02-14.wav\n",
      "03-01-02-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-02-01-14.wav\n",
      "03-01-02-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-02-02-14.wav\n",
      "03-01-02-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-01-01-14.wav\n",
      "03-01-02-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-01-02-14.wav\n",
      "03-01-02-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-02-01-14.wav\n",
      "03-01-02-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-02-02-14.wav\n",
      "03-01-02-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-01-01-14.wav\n",
      "03-01-03-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-01-02-14.wav\n",
      "03-01-03-01-01-02-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-02-01-14.wav\n",
      "03-01-03-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-02-02-14.wav\n",
      "03-01-03-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-01-01-14.wav\n",
      "03-01-03-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-01-02-14.wav\n",
      "03-01-03-02-01-02-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-02-01-14.wav\n",
      "03-01-03-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-02-02-14.wav\n",
      "03-01-03-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-01-01-14.wav\n",
      "03-01-04-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-01-02-14.wav\n",
      "03-01-04-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-02-01-14.wav\n",
      "03-01-04-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-02-02-14.wav\n",
      "03-01-04-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-01-01-14.wav\n",
      "03-01-04-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-01-02-14.wav\n",
      "03-01-04-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-02-01-14.wav\n",
      "03-01-04-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-02-02-14.wav\n",
      "03-01-04-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-01-01-14.wav\n",
      "03-01-05-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-01-02-14.wav\n",
      "03-01-05-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-02-01-14.wav\n",
      "03-01-05-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-02-02-14.wav\n",
      "03-01-05-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-01-01-14.wav\n",
      "03-01-05-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-01-02-14.wav\n",
      "03-01-05-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-02-01-14.wav\n",
      "03-01-05-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-02-02-14.wav\n",
      "03-01-05-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-01-01-14.wav\n",
      "03-01-06-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-01-02-14.wav\n",
      "03-01-06-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-02-01-14.wav\n",
      "03-01-06-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-02-02-14.wav\n",
      "03-01-06-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-01-01-14.wav\n",
      "03-01-06-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-01-02-14.wav\n",
      "03-01-06-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-02-01-14.wav\n",
      "03-01-06-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-02-02-14.wav\n",
      "03-01-06-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-01-01-14.wav\n",
      "03-01-07-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-01-02-14.wav\n",
      "03-01-07-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-02-01-14.wav\n",
      "03-01-07-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-02-02-14.wav\n",
      "03-01-07-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-01-01-14.wav\n",
      "03-01-07-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-01-02-14.wav\n",
      "03-01-07-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-02-01-14.wav\n",
      "03-01-07-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-02-02-14.wav\n",
      "03-01-07-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-01-01-14.wav\n",
      "03-01-08-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-01-02-14.wav\n",
      "03-01-08-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-02-01-14.wav\n",
      "03-01-08-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-02-02-14.wav\n",
      "03-01-08-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-01-01-14.wav\n",
      "03-01-08-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-01-02-14.wav\n",
      "03-01-08-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-02-01-14.wav\n",
      "03-01-08-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-02-02-14.wav\n",
      "03-01-08-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-01-01-15.wav\n",
      "03-01-01-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-01-02-15.wav\n",
      "03-01-01-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-02-01-15.wav\n",
      "03-01-01-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-02-02-15.wav\n",
      "03-01-01-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-01-01-15.wav\n",
      "03-01-02-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-01-02-15.wav\n",
      "03-01-02-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-02-01-15.wav\n",
      "03-01-02-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-02-02-15.wav\n",
      "03-01-02-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-01-01-15.wav\n",
      "03-01-02-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-01-02-15.wav\n",
      "03-01-02-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-02-01-15.wav\n",
      "03-01-02-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-02-02-15.wav\n",
      "03-01-02-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-01-01-15.wav\n",
      "03-01-03-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-01-02-15.wav\n",
      "03-01-03-01-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 1.2207031e-04 1.2207031e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00210571 -0.00216675\n",
      " -0.0020752 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-02-01-15.wav\n",
      "03-01-03-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-02-02-15.wav\n",
      "03-01-03-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-01-01-15.wav\n",
      "03-01-03-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-01-02-15.wav\n",
      "03-01-03-02-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 1.2207031e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 0.0000000e+00 3.0517578e-05 ... 1.5258789e-04 1.5258789e-04\n",
      " 1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-02-01-15.wav\n",
      "03-01-03-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-02-02-15.wav\n",
      "03-01-03-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-01-01-15.wav\n",
      "03-01-04-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-01-02-15.wav\n",
      "03-01-04-01-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -1.5258789e-04 -1.5258789e-04 ...  9.1552734e-05\n",
      "  9.1552734e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  1.5258789e-04\n",
      "  1.5258789e-04  1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-02-01-15.wav\n",
      "03-01-04-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-02-02-15.wav\n",
      "03-01-04-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-01-01-15.wav\n",
      "03-01-04-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-01-02-15.wav\n",
      "03-01-04-02-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00042725 0.00042725 0.00042725] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -1.2207031e-04 -1.2207031e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  1.3732910e-03\n",
      "  1.4038086e-03  1.4343262e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  3.0517578e-05  1.2207031e-04 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-02-01-15.wav\n",
      "03-01-04-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-02-02-15.wav\n",
      "03-01-04-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-01-01-15.wav\n",
      "03-01-05-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-01-02-15.wav\n",
      "03-01-05-01-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.2207031e-04\n",
      " -1.5258789e-04 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-02-01-15.wav\n",
      "03-01-05-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-02-02-15.wav\n",
      "03-01-05-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-01-01-15.wav\n",
      "03-01-05-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-01-02-15.wav\n",
      "03-01-05-02-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00012207 -0.00012207\n",
      " -0.00012207] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  1.2207031e-04\n",
      "  1.5258789e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-02-01-15.wav\n",
      "03-01-05-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-02-02-15.wav\n",
      "03-01-05-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-01-01-15.wav\n",
      "03-01-06-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-01-02-15.wav\n",
      "03-01-06-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-02-01-15.wav\n",
      "03-01-06-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-02-02-15.wav\n",
      "03-01-06-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-01-01-15.wav\n",
      "03-01-06-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-01-02-15.wav\n",
      "03-01-06-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-02-01-15.wav\n",
      "03-01-06-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-02-02-15.wav\n",
      "03-01-06-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-01-01-15.wav\n",
      "03-01-07-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-01-02-15.wav\n",
      "03-01-07-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-02-01-15.wav\n",
      "03-01-07-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-02-02-15.wav\n",
      "03-01-07-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-01-01-15.wav\n",
      "03-01-07-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-01-02-15.wav\n",
      "03-01-07-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-02-01-15.wav\n",
      "03-01-07-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-02-02-15.wav\n",
      "03-01-07-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-01-01-15.wav\n",
      "03-01-08-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-01-02-15.wav\n",
      "03-01-08-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-02-01-15.wav\n",
      "03-01-08-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-02-02-15.wav\n",
      "03-01-08-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-01-01-15.wav\n",
      "03-01-08-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-01-02-15.wav\n",
      "03-01-08-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-02-01-15.wav\n",
      "03-01-08-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-02-02-15.wav\n",
      "03-01-08-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-01-01-16.wav\n",
      "03-01-01-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-01-02-16.wav\n",
      "03-01-01-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-02-01-16.wav\n",
      "03-01-01-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-02-02-16.wav\n",
      "03-01-01-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-01-01-16.wav\n",
      "03-01-02-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-01-02-16.wav\n",
      "03-01-02-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-02-01-16.wav\n",
      "03-01-02-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-02-02-16.wav\n",
      "03-01-02-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-01-01-16.wav\n",
      "03-01-02-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-01-02-16.wav\n",
      "03-01-02-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-02-01-16.wav\n",
      "03-01-02-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-02-02-16.wav\n",
      "03-01-02-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-01-01-16.wav\n",
      "03-01-03-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-01-02-16.wav\n",
      "03-01-03-01-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 6.1035156e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-02-01-16.wav\n",
      "03-01-03-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-02-02-16.wav\n",
      "03-01-03-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-01-01-16.wav\n",
      "03-01-03-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-01-02-16.wav\n",
      "03-01-03-02-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-02-01-16.wav\n",
      "03-01-03-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-02-02-16.wav\n",
      "03-01-03-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-01-01-16.wav\n",
      "03-01-04-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-01-02-16.wav\n",
      "03-01-04-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-02-01-16.wav\n",
      "03-01-04-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-02-02-16.wav\n",
      "03-01-04-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-01-01-16.wav\n",
      "03-01-04-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-01-02-16.wav\n",
      "03-01-04-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-02-01-16.wav\n",
      "03-01-04-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-02-02-16.wav\n",
      "03-01-04-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-01-01-16.wav\n",
      "03-01-05-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-01-02-16.wav\n",
      "03-01-05-01-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -6.1035156e-05 -1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-02-01-16.wav\n",
      "03-01-05-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-02-02-16.wav\n",
      "03-01-05-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-01-01-16.wav\n",
      "03-01-05-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-01-02-16.wav\n",
      "03-01-05-02-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-02-01-16.wav\n",
      "03-01-05-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-02-02-16.wav\n",
      "03-01-05-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-01-01-16.wav\n",
      "03-01-06-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-01-02-16.wav\n",
      "03-01-06-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-02-01-16.wav\n",
      "03-01-06-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-02-02-16.wav\n",
      "03-01-06-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-01-01-16.wav\n",
      "03-01-06-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-01-02-16.wav\n",
      "03-01-06-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-02-01-16.wav\n",
      "03-01-06-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-02-02-16.wav\n",
      "03-01-06-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-01-01-16.wav\n",
      "03-01-07-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-01-02-16.wav\n",
      "03-01-07-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-02-01-16.wav\n",
      "03-01-07-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-02-02-16.wav\n",
      "03-01-07-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-01-01-16.wav\n",
      "03-01-07-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-01-02-16.wav\n",
      "03-01-07-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-02-01-16.wav\n",
      "03-01-07-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-02-02-16.wav\n",
      "03-01-07-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-01-01-16.wav\n",
      "03-01-08-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-01-02-16.wav\n",
      "03-01-08-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-02-01-16.wav\n",
      "03-01-08-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-02-02-16.wav\n",
      "03-01-08-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-01-01-16.wav\n",
      "03-01-08-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-01-02-16.wav\n",
      "03-01-08-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-02-01-16.wav\n",
      "03-01-08-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-02-02-16.wav\n",
      "03-01-08-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-01-01-17.wav\n",
      "03-01-01-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-01-02-17.wav\n",
      "03-01-01-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-04  3.3569336e-04  3.0517578e-04 ... -9.1552734e-05\n",
      " -9.1552734e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 9.1552734e-05 6.1035156e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -9.1552734e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-02-01-17.wav\n",
      "03-01-01-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-02-02-17.wav\n",
      "03-01-01-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-01-01-17.wav\n",
      "03-01-02-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-01-02-17.wav\n",
      "03-01-02-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-02-01-17.wav\n",
      "03-01-02-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-02-02-17.wav\n",
      "03-01-02-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-01-01-17.wav\n",
      "03-01-02-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-01-02-17.wav\n",
      "03-01-02-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-02-01-17.wav\n",
      "03-01-02-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-02-02-17.wav\n",
      "03-01-02-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-01-01-17.wav\n",
      "03-01-03-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-01-02-17.wav\n",
      "03-01-03-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  6.1035156e-05 ... -9.1552734e-05\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-2.1362305e-04 -9.1552734e-05  0.0000000e+00 ... -1.2207031e-04\n",
      " -1.5258789e-04 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 9.1552734e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.5258789e-04 3.0517578e-05 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-02-01-17.wav\n",
      "03-01-03-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-02-02-17.wav\n",
      "03-01-03-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-01-01-17.wav\n",
      "03-01-03-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-01-02-17.wav\n",
      "03-01-03-02-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.5258789e-04 ... -2.4414062e-04\n",
      " -9.1552734e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.3569336e-04 -9.1552734e-05  3.9672852e-04 ...  1.5258789e-04\n",
      "  1.2207031e-04  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 1.8310547e-04  1.8310547e-04  6.1035156e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-02-01-17.wav\n",
      "03-01-03-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-02-02-17.wav\n",
      "03-01-03-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-01-01-17.wav\n",
      "03-01-04-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-01-02-17.wav\n",
      "03-01-04-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 1.2207031e-04 1.5258789e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00012207 -0.00015259 -0.00018311 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 9.1552734e-05 9.1552734e-05 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00018311 0.00018311 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-02-01-17.wav\n",
      "03-01-04-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-02-02-17.wav\n",
      "03-01-04-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-01-01-17.wav\n",
      "03-01-04-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-01-02-17.wav\n",
      "03-01-04-02-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.2207031e-04 3.0517578e-05 ... 1.2207031e-04 1.2207031e-04\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-04 -3.3569336e-04 -5.7983398e-04 ...  6.1035156e-05\n",
      "  9.1552734e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-02-01-17.wav\n",
      "03-01-04-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-02-02-17.wav\n",
      "03-01-04-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-01-01-17.wav\n",
      "03-01-05-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-01-02-17.wav\n",
      "03-01-05-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -6.1035156e-05 -6.1035156e-05 ... -1.5258789e-04\n",
      " -1.5258789e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ... -1.2207031e-04\n",
      " -1.5258789e-04 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[1.2207031e-04 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-02-01-17.wav\n",
      "03-01-05-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-02-02-17.wav\n",
      "03-01-05-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-01-01-17.wav\n",
      "03-01-05-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-01-02-17.wav\n",
      "03-01-05-02-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -6.1035156e-05 -1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.00018311 0.00018311 0.00018311 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-2.4414062e-04 -9.1552734e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-02-01-17.wav\n",
      "03-01-05-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-02-02-17.wav\n",
      "03-01-05-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-01-01-17.wav\n",
      "03-01-06-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-01-02-17.wav\n",
      "03-01-06-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-02-01-17.wav\n",
      "03-01-06-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-02-02-17.wav\n",
      "03-01-06-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-01-01-17.wav\n",
      "03-01-06-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-01-02-17.wav\n",
      "03-01-06-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-02-01-17.wav\n",
      "03-01-06-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-02-02-17.wav\n",
      "03-01-06-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-01-01-17.wav\n",
      "03-01-07-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-01-02-17.wav\n",
      "03-01-07-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-02-01-17.wav\n",
      "03-01-07-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-02-02-17.wav\n",
      "03-01-07-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-01-01-17.wav\n",
      "03-01-07-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-01-02-17.wav\n",
      "03-01-07-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-02-01-17.wav\n",
      "03-01-07-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-02-02-17.wav\n",
      "03-01-07-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-01-01-17.wav\n",
      "03-01-08-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-01-02-17.wav\n",
      "03-01-08-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-02-01-17.wav\n",
      "03-01-08-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-02-02-17.wav\n",
      "03-01-08-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-01-01-17.wav\n",
      "03-01-08-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-01-02-17.wav\n",
      "03-01-08-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-02-01-17.wav\n",
      "03-01-08-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-02-02-17.wav\n",
      "03-01-08-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-01-01-18.wav\n",
      "03-01-01-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-01-02-18.wav\n",
      "03-01-01-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-02-01-18.wav\n",
      "03-01-01-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-02-02-18.wav\n",
      "03-01-01-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-01-01-18.wav\n",
      "03-01-02-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-01-02-18.wav\n",
      "03-01-02-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-02-01-18.wav\n",
      "03-01-02-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-02-02-18.wav\n",
      "03-01-02-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-01-01-18.wav\n",
      "03-01-02-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-01-02-18.wav\n",
      "03-01-02-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-02-01-18.wav\n",
      "03-01-02-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-02-02-18.wav\n",
      "03-01-02-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-01-01-18.wav\n",
      "03-01-03-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-01-02-18.wav\n",
      "03-01-03-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-02-01-18.wav\n",
      "03-01-03-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-02-02-18.wav\n",
      "03-01-03-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-01-01-18.wav\n",
      "03-01-03-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-01-02-18.wav\n",
      "03-01-03-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-02-01-18.wav\n",
      "03-01-03-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-02-02-18.wav\n",
      "03-01-03-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-01-01-18.wav\n",
      "03-01-04-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-01-02-18.wav\n",
      "03-01-04-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-02-01-18.wav\n",
      "03-01-04-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-02-02-18.wav\n",
      "03-01-04-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-01-01-18.wav\n",
      "03-01-04-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-01-02-18.wav\n",
      "03-01-04-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-02-01-18.wav\n",
      "03-01-04-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-02-02-18.wav\n",
      "03-01-04-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-01-01-18.wav\n",
      "03-01-05-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-01-02-18.wav\n",
      "03-01-05-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-02-01-18.wav\n",
      "03-01-05-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-02-02-18.wav\n",
      "03-01-05-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-01-01-18.wav\n",
      "03-01-05-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-01-02-18.wav\n",
      "03-01-05-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-02-01-18.wav\n",
      "03-01-05-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-02-02-18.wav\n",
      "03-01-05-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-01-01-18.wav\n",
      "03-01-06-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-01-02-18.wav\n",
      "03-01-06-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-02-01-18.wav\n",
      "03-01-06-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-02-02-18.wav\n",
      "03-01-06-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-01-01-18.wav\n",
      "03-01-06-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-01-02-18.wav\n",
      "03-01-06-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-02-01-18.wav\n",
      "03-01-06-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-02-02-18.wav\n",
      "03-01-06-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-01-01-18.wav\n",
      "03-01-07-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-01-02-18.wav\n",
      "03-01-07-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-02-01-18.wav\n",
      "03-01-07-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-02-02-18.wav\n",
      "03-01-07-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-01-01-18.wav\n",
      "03-01-07-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-01-02-18.wav\n",
      "03-01-07-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-02-01-18.wav\n",
      "03-01-07-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-02-02-18.wav\n",
      "03-01-07-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-01-01-18.wav\n",
      "03-01-08-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-01-02-18.wav\n",
      "03-01-08-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-02-01-18.wav\n",
      "03-01-08-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-02-02-18.wav\n",
      "03-01-08-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-01-01-18.wav\n",
      "03-01-08-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-01-02-18.wav\n",
      "03-01-08-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-02-01-18.wav\n",
      "03-01-08-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-02-02-18.wav\n",
      "03-01-08-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-01-01-19.wav\n",
      "03-01-01-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-01-02-19.wav\n",
      "03-01-01-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-02-01-19.wav\n",
      "03-01-01-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-02-02-19.wav\n",
      "03-01-01-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-01-01-19.wav\n",
      "03-01-02-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-01-02-19.wav\n",
      "03-01-02-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-02-01-19.wav\n",
      "03-01-02-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-02-02-19.wav\n",
      "03-01-02-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-01-01-19.wav\n",
      "03-01-02-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-01-02-19.wav\n",
      "03-01-02-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-02-01-19.wav\n",
      "03-01-02-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-02-02-19.wav\n",
      "03-01-02-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-01-01-19.wav\n",
      "03-01-03-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-01-02-19.wav\n",
      "03-01-03-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00018311 -0.00018311 -0.00021362 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00308228 0.00311279 0.00308228] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-02-01-19.wav\n",
      "03-01-03-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-02-02-19.wav\n",
      "03-01-03-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-01-01-19.wav\n",
      "03-01-03-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-01-02-19.wav\n",
      "03-01-03-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 0.0000000e+00 ... 9.1552734e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -1.2207031e-04 ...  9.1552734e-05\n",
      "  9.1552734e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.00036621  0.00045776  0.00048828 ... -0.00021362 -0.00021362\n",
      " -0.00021362] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-02-01-19.wav\n",
      "03-01-03-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-02-02-19.wav\n",
      "03-01-03-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-01-01-19.wav\n",
      "03-01-04-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-01-02-19.wav\n",
      "03-01-04-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.00067139  0.00076294  0.00106812 ...  0.00344849 -0.00195312\n",
      " -0.00204468] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -1.2207031e-04 ...  3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 6.1035156e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-02-01-19.wav\n",
      "03-01-04-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-02-02-19.wav\n",
      "03-01-04-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-01-01-19.wav\n",
      "03-01-04-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-01-02-19.wav\n",
      "03-01-04-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00125122 -0.00125122\n",
      " -0.00125122] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.0022583  -0.00228882 -0.00234985 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-02-01-19.wav\n",
      "03-01-04-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-02-02-19.wav\n",
      "03-01-04-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-01-01-19.wav\n",
      "03-01-05-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-01-02-19.wav\n",
      "03-01-05-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00048828 -0.00036621 -0.00027466 ... -0.00021362 -0.00021362\n",
      " -0.00021362] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -9.1552734e-05 ...  3.9672852e-04\n",
      "  3.9672852e-04  3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-02-01-19.wav\n",
      "03-01-05-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-02-02-19.wav\n",
      "03-01-05-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-01-01-19.wav\n",
      "03-01-05-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-01-02-19.wav\n",
      "03-01-05-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-0.00283813 -0.00286865 -0.00286865 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-02-01-19.wav\n",
      "03-01-05-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-02-02-19.wav\n",
      "03-01-05-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-01-01-19.wav\n",
      "03-01-06-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-01-02-19.wav\n",
      "03-01-06-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-02-01-19.wav\n",
      "03-01-06-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-02-02-19.wav\n",
      "03-01-06-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-01-01-19.wav\n",
      "03-01-06-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-01-02-19.wav\n",
      "03-01-06-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-02-01-19.wav\n",
      "03-01-06-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-02-02-19.wav\n",
      "03-01-06-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-01-01-19.wav\n",
      "03-01-07-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-01-02-19.wav\n",
      "03-01-07-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-02-01-19.wav\n",
      "03-01-07-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-02-02-19.wav\n",
      "03-01-07-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-01-01-19.wav\n",
      "03-01-07-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-01-02-19.wav\n",
      "03-01-07-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-02-01-19.wav\n",
      "03-01-07-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-02-02-19.wav\n",
      "03-01-07-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-01-01-19.wav\n",
      "03-01-08-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-01-02-19.wav\n",
      "03-01-08-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-02-01-19.wav\n",
      "03-01-08-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-02-02-19.wav\n",
      "03-01-08-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-01-01-19.wav\n",
      "03-01-08-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-01-02-19.wav\n",
      "03-01-08-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-02-01-19.wav\n",
      "03-01-08-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-02-02-19.wav\n",
      "03-01-08-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-01-01-20.wav\n",
      "03-01-01-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-01-02-20.wav\n",
      "03-01-01-01-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05 -3.0517578e-05  2.1362305e-04 ...  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-02-01-20.wav\n",
      "03-01-01-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-02-02-20.wav\n",
      "03-01-01-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-01-01-20.wav\n",
      "03-01-02-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-01-02-20.wav\n",
      "03-01-02-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-02-01-20.wav\n",
      "03-01-02-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-02-02-20.wav\n",
      "03-01-02-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-01-01-20.wav\n",
      "03-01-02-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-01-02-20.wav\n",
      "03-01-02-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-02-01-20.wav\n",
      "03-01-02-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-02-02-20.wav\n",
      "03-01-02-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-01-01-20.wav\n",
      "03-01-03-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-01-02-20.wav\n",
      "03-01-03-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-02-01-20.wav\n",
      "03-01-03-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-02-02-20.wav\n",
      "03-01-03-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-01-01-20.wav\n",
      "03-01-03-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-01-02-20.wav\n",
      "03-01-03-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-02-01-20.wav\n",
      "03-01-03-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-02-02-20.wav\n",
      "03-01-03-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-01-01-20.wav\n",
      "03-01-04-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-01-02-20.wav\n",
      "03-01-04-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-02-01-20.wav\n",
      "03-01-04-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-02-02-20.wav\n",
      "03-01-04-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-01-01-20.wav\n",
      "03-01-04-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-01-02-20.wav\n",
      "03-01-04-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.01150513 -0.0135498\n",
      "  0.01361084] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-02-01-20.wav\n",
      "03-01-04-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-02-02-20.wav\n",
      "03-01-04-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-01-01-20.wav\n",
      "03-01-05-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-01-02-20.wav\n",
      "03-01-05-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-02-01-20.wav\n",
      "03-01-05-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-02-02-20.wav\n",
      "03-01-05-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-01-01-20.wav\n",
      "03-01-05-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-01-02-20.wav\n",
      "03-01-05-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-02-01-20.wav\n",
      "03-01-05-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-02-02-20.wav\n",
      "03-01-05-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-01-01-20.wav\n",
      "03-01-06-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-01-02-20.wav\n",
      "03-01-06-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-02-01-20.wav\n",
      "03-01-06-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-02-02-20.wav\n",
      "03-01-06-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-01-01-20.wav\n",
      "03-01-06-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-01-02-20.wav\n",
      "03-01-06-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-02-01-20.wav\n",
      "03-01-06-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-02-02-20.wav\n",
      "03-01-06-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-01-01-20.wav\n",
      "03-01-07-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-01-02-20.wav\n",
      "03-01-07-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-02-01-20.wav\n",
      "03-01-07-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-02-02-20.wav\n",
      "03-01-07-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-01-01-20.wav\n",
      "03-01-07-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-01-02-20.wav\n",
      "03-01-07-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-02-01-20.wav\n",
      "03-01-07-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-02-02-20.wav\n",
      "03-01-07-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-01-01-20.wav\n",
      "03-01-08-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-01-02-20.wav\n",
      "03-01-08-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-02-01-20.wav\n",
      "03-01-08-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-02-02-20.wav\n",
      "03-01-08-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-01-01-20.wav\n",
      "03-01-08-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-01-02-20.wav\n",
      "03-01-08-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-02-01-20.wav\n",
      "03-01-08-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-02-02-20.wav\n",
      "03-01-08-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-01-01-21.wav\n",
      "03-01-01-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-01-02-21.wav\n",
      "03-01-01-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-02-01-21.wav\n",
      "03-01-01-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-02-02-21.wav\n",
      "03-01-01-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-01-01-21.wav\n",
      "03-01-02-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-01-02-21.wav\n",
      "03-01-02-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-02-01-21.wav\n",
      "03-01-02-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-02-02-21.wav\n",
      "03-01-02-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-01-01-21.wav\n",
      "03-01-02-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-01-02-21.wav\n",
      "03-01-02-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-02-01-21.wav\n",
      "03-01-02-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-02-02-21.wav\n",
      "03-01-02-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-01-01-21.wav\n",
      "03-01-03-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-01-02-21.wav\n",
      "03-01-03-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-02-01-21.wav\n",
      "03-01-03-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-02-02-21.wav\n",
      "03-01-03-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-01-01-21.wav\n",
      "03-01-03-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-01-02-21.wav\n",
      "03-01-03-02-01-02-21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-02-01-21.wav\n",
      "03-01-03-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-02-02-21.wav\n",
      "03-01-03-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-01-01-21.wav\n",
      "03-01-04-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-01-02-21.wav\n",
      "03-01-04-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-02-01-21.wav\n",
      "03-01-04-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-02-02-21.wav\n",
      "03-01-04-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-01-01-21.wav\n",
      "03-01-04-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-01-02-21.wav\n",
      "03-01-04-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-02-01-21.wav\n",
      "03-01-04-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-02-02-21.wav\n",
      "03-01-04-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-01-01-21.wav\n",
      "03-01-05-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-01-02-21.wav\n",
      "03-01-05-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-02-01-21.wav\n",
      "03-01-05-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-02-02-21.wav\n",
      "03-01-05-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-01-01-21.wav\n",
      "03-01-05-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-01-02-21.wav\n",
      "03-01-05-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-02-01-21.wav\n",
      "03-01-05-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-02-02-21.wav\n",
      "03-01-05-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-01-01-21.wav\n",
      "03-01-06-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-01-02-21.wav\n",
      "03-01-06-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-02-01-21.wav\n",
      "03-01-06-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-02-02-21.wav\n",
      "03-01-06-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-01-01-21.wav\n",
      "03-01-06-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-01-02-21.wav\n",
      "03-01-06-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-02-01-21.wav\n",
      "03-01-06-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-02-02-21.wav\n",
      "03-01-06-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-01-01-21.wav\n",
      "03-01-07-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-01-02-21.wav\n",
      "03-01-07-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-02-01-21.wav\n",
      "03-01-07-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-02-02-21.wav\n",
      "03-01-07-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-01-01-21.wav\n",
      "03-01-07-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-01-02-21.wav\n",
      "03-01-07-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-02-01-21.wav\n",
      "03-01-07-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-02-02-21.wav\n",
      "03-01-07-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-01-01-21.wav\n",
      "03-01-08-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-01-02-21.wav\n",
      "03-01-08-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-02-01-21.wav\n",
      "03-01-08-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-02-02-21.wav\n",
      "03-01-08-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-01-01-21.wav\n",
      "03-01-08-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-01-02-21.wav\n",
      "03-01-08-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-02-01-21.wav\n",
      "03-01-08-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-02-02-21.wav\n",
      "03-01-08-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-01-01-22.wav\n",
      "03-01-01-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-01-02-22.wav\n",
      "03-01-01-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-02-01-22.wav\n",
      "03-01-01-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-02-02-22.wav\n",
      "03-01-01-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-01-01-22.wav\n",
      "03-01-02-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-01-02-22.wav\n",
      "03-01-02-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-02-01-22.wav\n",
      "03-01-02-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-02-02-22.wav\n",
      "03-01-02-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-01-01-22.wav\n",
      "03-01-02-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-01-02-22.wav\n",
      "03-01-02-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-02-01-22.wav\n",
      "03-01-02-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-02-02-22.wav\n",
      "03-01-02-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-01-01-22.wav\n",
      "03-01-03-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-01-02-22.wav\n",
      "03-01-03-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-02-01-22.wav\n",
      "03-01-03-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-02-02-22.wav\n",
      "03-01-03-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-01-01-22.wav\n",
      "03-01-03-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-01-02-22.wav\n",
      "03-01-03-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-02-01-22.wav\n",
      "03-01-03-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-02-02-22.wav\n",
      "03-01-03-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-01-01-22.wav\n",
      "03-01-04-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-01-02-22.wav\n",
      "03-01-04-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-02-01-22.wav\n",
      "03-01-04-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-02-02-22.wav\n",
      "03-01-04-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-01-01-22.wav\n",
      "03-01-04-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-01-02-22.wav\n",
      "03-01-04-02-01-02-22.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-02-01-22.wav\n",
      "03-01-04-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-02-02-22.wav\n",
      "03-01-04-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-01-01-22.wav\n",
      "03-01-05-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-01-02-22.wav\n",
      "03-01-05-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-02-01-22.wav\n",
      "03-01-05-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-02-02-22.wav\n",
      "03-01-05-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-01-01-22.wav\n",
      "03-01-05-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-01-02-22.wav\n",
      "03-01-05-02-01-02-22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-02-01-22.wav\n",
      "03-01-05-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-02-02-22.wav\n",
      "03-01-05-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-01-01-22.wav\n",
      "03-01-06-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-01-02-22.wav\n",
      "03-01-06-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-02-01-22.wav\n",
      "03-01-06-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-02-02-22.wav\n",
      "03-01-06-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-01-01-22.wav\n",
      "03-01-06-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-01-02-22.wav\n",
      "03-01-06-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-02-01-22.wav\n",
      "03-01-06-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-02-02-22.wav\n",
      "03-01-06-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-01-01-22.wav\n",
      "03-01-07-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-01-02-22.wav\n",
      "03-01-07-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-02-01-22.wav\n",
      "03-01-07-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-02-02-22.wav\n",
      "03-01-07-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-01-01-22.wav\n",
      "03-01-07-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-01-02-22.wav\n",
      "03-01-07-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-02-01-22.wav\n",
      "03-01-07-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-02-02-22.wav\n",
      "03-01-07-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-01-01-22.wav\n",
      "03-01-08-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-01-02-22.wav\n",
      "03-01-08-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-02-01-22.wav\n",
      "03-01-08-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-02-02-22.wav\n",
      "03-01-08-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-01-01-22.wav\n",
      "03-01-08-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-01-02-22.wav\n",
      "03-01-08-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-02-01-22.wav\n",
      "03-01-08-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-02-02-22.wav\n",
      "03-01-08-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-01-01-23.wav\n",
      "03-01-01-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-01-02-23.wav\n",
      "03-01-01-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-02-01-23.wav\n",
      "03-01-01-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-02-02-23.wav\n",
      "03-01-01-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-01-01-23.wav\n",
      "03-01-02-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-01-02-23.wav\n",
      "03-01-02-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-02-01-23.wav\n",
      "03-01-02-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-02-02-23.wav\n",
      "03-01-02-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-01-01-23.wav\n",
      "03-01-02-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-01-02-23.wav\n",
      "03-01-02-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-02-01-23.wav\n",
      "03-01-02-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-02-02-23.wav\n",
      "03-01-02-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-01-01-23.wav\n",
      "03-01-03-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-01-02-23.wav\n",
      "03-01-03-01-01-02-23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-02-01-23.wav\n",
      "03-01-03-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-02-02-23.wav\n",
      "03-01-03-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-01-01-23.wav\n",
      "03-01-03-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-01-02-23.wav\n",
      "03-01-03-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-02-01-23.wav\n",
      "03-01-03-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-02-02-23.wav\n",
      "03-01-03-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-01-01-23.wav\n",
      "03-01-04-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-01-02-23.wav\n",
      "03-01-04-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-02-01-23.wav\n",
      "03-01-04-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-02-02-23.wav\n",
      "03-01-04-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-01-01-23.wav\n",
      "03-01-04-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-01-02-23.wav\n",
      "03-01-04-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-02-01-23.wav\n",
      "03-01-04-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-02-02-23.wav\n",
      "03-01-04-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-01-01-23.wav\n",
      "03-01-05-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-01-02-23.wav\n",
      "03-01-05-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-02-01-23.wav\n",
      "03-01-05-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-02-02-23.wav\n",
      "03-01-05-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-01-01-23.wav\n",
      "03-01-05-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-01-02-23.wav\n",
      "03-01-05-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-02-01-23.wav\n",
      "03-01-05-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-02-02-23.wav\n",
      "03-01-05-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-01-01-23.wav\n",
      "03-01-06-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-01-02-23.wav\n",
      "03-01-06-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-02-01-23.wav\n",
      "03-01-06-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-02-02-23.wav\n",
      "03-01-06-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-01-01-23.wav\n",
      "03-01-06-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-01-02-23.wav\n",
      "03-01-06-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-02-01-23.wav\n",
      "03-01-06-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-02-02-23.wav\n",
      "03-01-06-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-01-01-23.wav\n",
      "03-01-07-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-01-02-23.wav\n",
      "03-01-07-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-02-01-23.wav\n",
      "03-01-07-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-02-02-23.wav\n",
      "03-01-07-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-01-01-23.wav\n",
      "03-01-07-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-01-02-23.wav\n",
      "03-01-07-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-02-01-23.wav\n",
      "03-01-07-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-02-02-23.wav\n",
      "03-01-07-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-01-01-23.wav\n",
      "03-01-08-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-01-02-23.wav\n",
      "03-01-08-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-02-01-23.wav\n",
      "03-01-08-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-02-02-23.wav\n",
      "03-01-08-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-01-01-23.wav\n",
      "03-01-08-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-01-02-23.wav\n",
      "03-01-08-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-02-01-23.wav\n",
      "03-01-08-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-02-02-23.wav\n",
      "03-01-08-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-01-01-24.wav\n",
      "03-01-01-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-01-02-24.wav\n",
      "03-01-01-01-01-02-24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-02-01-24.wav\n",
      "03-01-01-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-02-02-24.wav\n",
      "03-01-01-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-01-01-24.wav\n",
      "03-01-02-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-01-02-24.wav\n",
      "03-01-02-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-02-01-24.wav\n",
      "03-01-02-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-02-02-24.wav\n",
      "03-01-02-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-01-01-24.wav\n",
      "03-01-02-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-01-02-24.wav\n",
      "03-01-02-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-02-01-24.wav\n",
      "03-01-02-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-02-02-24.wav\n",
      "03-01-02-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-01-01-24.wav\n",
      "03-01-03-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-01-02-24.wav\n",
      "03-01-03-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-02-01-24.wav\n",
      "03-01-03-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-02-02-24.wav\n",
      "03-01-03-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-01-01-24.wav\n",
      "03-01-03-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-01-02-24.wav\n",
      "03-01-03-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-02-01-24.wav\n",
      "03-01-03-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-02-02-24.wav\n",
      "03-01-03-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-01-01-24.wav\n",
      "03-01-04-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-01-02-24.wav\n",
      "03-01-04-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-02-01-24.wav\n",
      "03-01-04-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-02-02-24.wav\n",
      "03-01-04-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-01-01-24.wav\n",
      "03-01-04-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-01-02-24.wav\n",
      "03-01-04-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-02-01-24.wav\n",
      "03-01-04-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-02-02-24.wav\n",
      "03-01-04-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-01-01-24.wav\n",
      "03-01-05-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-01-02-24.wav\n",
      "03-01-05-01-01-02-24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.5258789e-04\n",
      " -1.5258789e-04 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-02-01-24.wav\n",
      "03-01-05-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-02-02-24.wav\n",
      "03-01-05-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-01-01-24.wav\n",
      "03-01-05-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-01-02-24.wav\n",
      "03-01-05-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-02-01-24.wav\n",
      "03-01-05-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-02-02-24.wav\n",
      "03-01-05-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-01-01-24.wav\n",
      "03-01-06-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-01-02-24.wav\n",
      "03-01-06-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-02-01-24.wav\n",
      "03-01-06-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-02-02-24.wav\n",
      "03-01-06-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-01-01-24.wav\n",
      "03-01-06-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-01-02-24.wav\n",
      "03-01-06-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-02-01-24.wav\n",
      "03-01-06-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-02-02-24.wav\n",
      "03-01-06-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-01-01-24.wav\n",
      "03-01-07-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-01-02-24.wav\n",
      "03-01-07-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-02-01-24.wav\n",
      "03-01-07-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-02-02-24.wav\n",
      "03-01-07-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-01-01-24.wav\n",
      "03-01-07-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-01-02-24.wav\n",
      "03-01-07-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-02-01-24.wav\n",
      "03-01-07-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-02-02-24.wav\n",
      "03-01-07-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-01-01-24.wav\n",
      "03-01-08-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-01-02-24.wav\n",
      "03-01-08-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-02-01-24.wav\n",
      "03-01-08-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-02-02-24.wav\n",
      "03-01-08-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-01-01-24.wav\n",
      "03-01-08-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-01-02-24.wav\n",
      "03-01-08-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-02-01-24.wav\n",
      "03-01-08-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-02-02-24.wav\n",
      "03-01-08-02-02-02-24.wav\n",
      "[+] Number of training samples: 537\n",
      "[+] Number of testing samples: 135\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GO3OzGWt22Sq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((537, 180, 1), (135, 180, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train= np.asarray(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n",
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)\n",
    "x_traincnn.shape,x_testcnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HmqNzFs85Ck6",
    "outputId": "18ef3b9d-a617-4aa4-9667-b52712b79d3f"
   },
   "source": [
    "# Configuration 1 - CNN_Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhBOW8Rk5VKt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 22, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2816)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 22536     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,352\n",
      "Trainable params: 105,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))        #1\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))                           #2\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))                                                 #3\n",
    "model.add(Activation('softmax'))\n",
    "optimizer=keras.optimizers.Adam(lr=0.001)\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ecd7379031902068\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ecd7379031902068\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow\n",
    "%reload_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K6opFz235tL0",
    "outputId": "b509e32f-8d14-477c-d8a1-35e919a159d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 52ms/step - loss: 3.6104 - accuracy: 0.2868 - val_loss: 1.9997 - val_accuracy: 0.4074\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 2.0675 - accuracy: 0.3669 - val_loss: 1.8175 - val_accuracy: 0.3852\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.5852 - accuracy: 0.4004 - val_loss: 1.0315 - val_accuracy: 0.5926\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.3147 - accuracy: 0.4320 - val_loss: 1.1401 - val_accuracy: 0.5481\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.2737 - accuracy: 0.4693 - val_loss: 0.9805 - val_accuracy: 0.5704\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.0696 - accuracy: 0.5028 - val_loss: 1.0107 - val_accuracy: 0.5481\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.9987 - accuracy: 0.5251 - val_loss: 0.9986 - val_accuracy: 0.5778\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.0247 - accuracy: 0.5158 - val_loss: 0.8598 - val_accuracy: 0.6222\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.9679 - accuracy: 0.5493 - val_loss: 0.8887 - val_accuracy: 0.4815\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9373 - accuracy: 0.5661 - val_loss: 0.8753 - val_accuracy: 0.6222\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.9307 - accuracy: 0.5512 - val_loss: 0.9867 - val_accuracy: 0.5407\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.9310 - accuracy: 0.5773 - val_loss: 0.8693 - val_accuracy: 0.5259\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9108 - accuracy: 0.5829 - val_loss: 0.8131 - val_accuracy: 0.5926\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.9340 - accuracy: 0.5568 - val_loss: 0.8284 - val_accuracy: 0.6222\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.9066 - accuracy: 0.5922 - val_loss: 1.0439 - val_accuracy: 0.5481\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.8817 - accuracy: 0.6052 - val_loss: 0.8187 - val_accuracy: 0.6444\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.8355 - accuracy: 0.6164 - val_loss: 0.9367 - val_accuracy: 0.5704\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.8365 - accuracy: 0.6127 - val_loss: 0.8416 - val_accuracy: 0.6148\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.7881 - accuracy: 0.6257 - val_loss: 0.7900 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.7987 - accuracy: 0.6518 - val_loss: 1.3711 - val_accuracy: 0.6222\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.8378 - accuracy: 0.6555 - val_loss: 0.7569 - val_accuracy: 0.6222\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.7862 - accuracy: 0.6574 - val_loss: 0.9043 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.7858 - accuracy: 0.6462 - val_loss: 0.7608 - val_accuracy: 0.6593\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.7292 - accuracy: 0.7020 - val_loss: 0.8308 - val_accuracy: 0.6741\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.7887 - accuracy: 0.6536 - val_loss: 0.8533 - val_accuracy: 0.5704\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.7223 - accuracy: 0.7132 - val_loss: 1.0403 - val_accuracy: 0.6963\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.7776 - accuracy: 0.6872 - val_loss: 0.8211 - val_accuracy: 0.6148\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.7370 - accuracy: 0.6983 - val_loss: 0.7605 - val_accuracy: 0.6593\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.7201 - accuracy: 0.6778 - val_loss: 0.7053 - val_accuracy: 0.6815\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.6875 - accuracy: 0.7300 - val_loss: 0.7650 - val_accuracy: 0.6444\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.6700 - accuracy: 0.7207 - val_loss: 0.7815 - val_accuracy: 0.6222\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.6622 - accuracy: 0.7337 - val_loss: 0.6819 - val_accuracy: 0.6815\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.6455 - accuracy: 0.7337 - val_loss: 0.8401 - val_accuracy: 0.6593\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.6594 - accuracy: 0.7616 - val_loss: 0.7671 - val_accuracy: 0.6741\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.6327 - accuracy: 0.7505 - val_loss: 0.8030 - val_accuracy: 0.6593\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.5894 - accuracy: 0.7579 - val_loss: 0.7241 - val_accuracy: 0.6519\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.5705 - accuracy: 0.7728 - val_loss: 0.6438 - val_accuracy: 0.6815\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.5996 - accuracy: 0.7486 - val_loss: 0.6721 - val_accuracy: 0.6815\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.5515 - accuracy: 0.7933 - val_loss: 0.7378 - val_accuracy: 0.6741\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.5447 - accuracy: 0.7784 - val_loss: 0.6881 - val_accuracy: 0.6519\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.5178 - accuracy: 0.8138 - val_loss: 0.6580 - val_accuracy: 0.6593\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.5029 - accuracy: 0.8063 - val_loss: 0.6490 - val_accuracy: 0.6815\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.4964 - accuracy: 0.8026 - val_loss: 0.7201 - val_accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.5377 - accuracy: 0.7914 - val_loss: 0.6470 - val_accuracy: 0.7037\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.4856 - accuracy: 0.8082 - val_loss: 0.7568 - val_accuracy: 0.6370\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.4699 - accuracy: 0.8250 - val_loss: 0.6692 - val_accuracy: 0.7111\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.4792 - accuracy: 0.8250 - val_loss: 0.6386 - val_accuracy: 0.7111\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.4617 - accuracy: 0.8343 - val_loss: 0.6480 - val_accuracy: 0.7037\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.4179 - accuracy: 0.8529 - val_loss: 0.6416 - val_accuracy: 0.6889\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.4184 - accuracy: 0.8399 - val_loss: 0.6130 - val_accuracy: 0.7333\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRBYh-bMHucX"
   },
   "outputs": [],
   "source": [
    "em=['happy','sad','neutral','angry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Config-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GrrqoLzFAJDq",
    "outputId": "127a4973-55a9-4310-9df2-5d2ccef3f574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step\n",
      "sad\n",
      "[6.1088137e-02 5.9541394e-10 5.4965919e-22 5.9412667e-07 9.3891126e-01\n",
      " 5.4965977e-20 3.5417951e-21 2.1254096e-20]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_testcnn)\n",
    "n=predictions[1]\n",
    "print(em[1])\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CxJc4kIaD9IK",
    "outputId": "943689bb-a472-4a03-fd96-38a5d9e4c69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6130 - accuracy: 0.7333\n",
      "Restored model, accuracy: 73.33%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kVanJ86-FhwS",
    "outputId": "c8194727-9ef5-4e72-d1e2-26c6100cdb74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "result : happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10432\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    }
   ],
   "source": [
    "filename = \"C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset/Actor_02/03-01-01-01-02-01-02.wav\"\n",
    "features = np.array(extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
    "f=np.expand_dims(features,axis=2)\n",
    "result = model.predict(f)[0]\n",
    "print(\"result :\",em[int(result[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1vlkqDPlA8A"
   },
   "source": [
    "# Configuration 2 - CNN_RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQR38pmCSaNU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 22, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,920\n",
      "Trainable params: 166,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "um = Sequential()\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
    "um.add(Activation('relu'))\n",
    "um.add(Dropout(0.25))\n",
    "um.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',))                  #2\n",
    "um.add(Activation('relu'))\n",
    "um.add(MaxPooling1D(pool_size=(8)))\n",
    "um.add(Dropout(0.25))\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',))                  #3\n",
    "um.add(Activation('relu'))\n",
    "um.add(Dropout(0.25))\n",
    "\n",
    "um.add(Flatten())\n",
    "um.add(Dense(8))                                        #4                      \n",
    "um.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.00005,epsilon=None,rho=0.9,decay=0.0)\n",
    "\n",
    "um.summary()\n",
    "\n",
    "um.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0XiAWqd1bg5M",
    "outputId": "7c46bbcc-c4b1-425d-f06d-5f516ac6a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 52ms/step - loss: 10.5351 - accuracy: 0.1844 - val_loss: 2.3399 - val_accuracy: 0.3111\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 7.4845 - accuracy: 0.2663 - val_loss: 2.0101 - val_accuracy: 0.3778\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 6.7791 - accuracy: 0.2570 - val_loss: 1.9757 - val_accuracy: 0.4000\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 6.2133 - accuracy: 0.2886 - val_loss: 1.6708 - val_accuracy: 0.4000\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 5.6791 - accuracy: 0.2886 - val_loss: 1.5222 - val_accuracy: 0.4296\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 5.6620 - accuracy: 0.2924 - val_loss: 1.5472 - val_accuracy: 0.4667\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 4.4757 - accuracy: 0.3091 - val_loss: 1.4163 - val_accuracy: 0.4593\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 4.2296 - accuracy: 0.3017 - val_loss: 1.3539 - val_accuracy: 0.4815\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 4.0885 - accuracy: 0.2831 - val_loss: 1.2423 - val_accuracy: 0.5333\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 3.5150 - accuracy: 0.3538 - val_loss: 1.3481 - val_accuracy: 0.4074\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 3.6116 - accuracy: 0.3017 - val_loss: 1.2838 - val_accuracy: 0.4667\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 3.2527 - accuracy: 0.3240 - val_loss: 1.3344 - val_accuracy: 0.3630\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 2.9284 - accuracy: 0.3091 - val_loss: 1.2317 - val_accuracy: 0.4815\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 2.7982 - accuracy: 0.3445 - val_loss: 1.2469 - val_accuracy: 0.4963\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 2.6004 - accuracy: 0.3315 - val_loss: 1.2508 - val_accuracy: 0.4815\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 2.7103 - accuracy: 0.2942 - val_loss: 1.2668 - val_accuracy: 0.4667\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 2.4008 - accuracy: 0.3184 - val_loss: 1.2930 - val_accuracy: 0.4000\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 2.2092 - accuracy: 0.3184 - val_loss: 1.3067 - val_accuracy: 0.3778\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 2.1307 - accuracy: 0.3352 - val_loss: 1.2767 - val_accuracy: 0.4815\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 2.0417 - accuracy: 0.3631 - val_loss: 1.3402 - val_accuracy: 0.3185\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.9462 - accuracy: 0.3352 - val_loss: 1.2719 - val_accuracy: 0.3926\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.9297 - accuracy: 0.3426 - val_loss: 1.2528 - val_accuracy: 0.5185\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.7853 - accuracy: 0.3501 - val_loss: 1.2435 - val_accuracy: 0.4963\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.9179 - accuracy: 0.3277 - val_loss: 1.2730 - val_accuracy: 0.4963\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.7865 - accuracy: 0.3743 - val_loss: 1.2701 - val_accuracy: 0.4741\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.7777 - accuracy: 0.3687 - val_loss: 1.2604 - val_accuracy: 0.4889\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.6717 - accuracy: 0.3836 - val_loss: 1.2730 - val_accuracy: 0.5037\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.6811 - accuracy: 0.3520 - val_loss: 1.2879 - val_accuracy: 0.4148\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.6671 - accuracy: 0.3687 - val_loss: 1.2978 - val_accuracy: 0.4000\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.6818 - accuracy: 0.3464 - val_loss: 1.2780 - val_accuracy: 0.4741\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.5189 - accuracy: 0.3892 - val_loss: 1.2971 - val_accuracy: 0.4296\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.6262 - accuracy: 0.3520 - val_loss: 1.2845 - val_accuracy: 0.5037\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.5552 - accuracy: 0.3482 - val_loss: 1.2797 - val_accuracy: 0.4519\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.6164 - accuracy: 0.3575 - val_loss: 1.2734 - val_accuracy: 0.5185\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.5564 - accuracy: 0.3706 - val_loss: 1.2580 - val_accuracy: 0.5259\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.4932 - accuracy: 0.3836 - val_loss: 1.2453 - val_accuracy: 0.5037\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.5651 - accuracy: 0.3426 - val_loss: 1.2416 - val_accuracy: 0.5037\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.4558 - accuracy: 0.3724 - val_loss: 1.2522 - val_accuracy: 0.5259\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.5249 - accuracy: 0.3743 - val_loss: 1.2485 - val_accuracy: 0.5333\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.4763 - accuracy: 0.3520 - val_loss: 1.2544 - val_accuracy: 0.5259\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.4545 - accuracy: 0.3799 - val_loss: 1.2530 - val_accuracy: 0.5259\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.4222 - accuracy: 0.3836 - val_loss: 1.2645 - val_accuracy: 0.5259\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.4230 - accuracy: 0.3929 - val_loss: 1.2785 - val_accuracy: 0.5333\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.4440 - accuracy: 0.3669 - val_loss: 1.2804 - val_accuracy: 0.5259\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.4748 - accuracy: 0.3520 - val_loss: 1.2691 - val_accuracy: 0.5333\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.3114 - accuracy: 0.4395 - val_loss: 1.2342 - val_accuracy: 0.5037\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.3935 - accuracy: 0.4171 - val_loss: 1.2395 - val_accuracy: 0.5259\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.3420 - accuracy: 0.3836 - val_loss: 1.2535 - val_accuracy: 0.4815\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.4054 - accuracy: 0.3575 - val_loss: 1.2304 - val_accuracy: 0.5333\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.3484 - accuracy: 0.4060 - val_loss: 1.2431 - val_accuracy: 0.5111\n"
     ]
    }
   ],
   "source": [
    "umhistory=um.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18324), started 0:01:34 ago. (Use '!kill 18324' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f093863afa58ebf5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f093863afa58ebf5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Config - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUtQ8Bwjhcmw",
    "outputId": "e2fb5814-290f-47fe-b4e3-7dbaec5c432d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2431 - accuracy: 0.5111\n",
      "Restored model, accuracy: 51.11%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = um.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Abdy_mt4nABa"
   },
   "source": [
    "# Configuration 2 - CNN2_Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V43ptFvXm-bj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 22, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,968\n",
      "Trainable params: 248,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "sm = Sequential()\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "sm.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #2\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(MaxPooling1D(pool_size=(8)))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #3\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #4\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Flatten())\n",
    "sm.add(Dense(8))                                        #5                     \n",
    "sm.add(Activation('softmax'))\n",
    "\n",
    "sm.summary()\n",
    "sm.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 60ms/step - loss: 2.4588 - accuracy: 0.3035 - val_loss: 1.3615 - val_accuracy: 0.2889\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 1.4818 - accuracy: 0.3818 - val_loss: 1.2111 - val_accuracy: 0.4889\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 1.3046 - accuracy: 0.3873 - val_loss: 1.1635 - val_accuracy: 0.3630\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 1.3010 - accuracy: 0.3650 - val_loss: 1.2046 - val_accuracy: 0.3407\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 1.2527 - accuracy: 0.3985 - val_loss: 1.3391 - val_accuracy: 0.3852\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.2356 - accuracy: 0.4451 - val_loss: 1.2028 - val_accuracy: 0.4000\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.2148 - accuracy: 0.4562 - val_loss: 1.1768 - val_accuracy: 0.4222\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 1.1863 - accuracy: 0.4618 - val_loss: 1.0583 - val_accuracy: 0.5407\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 1.1735 - accuracy: 0.4637 - val_loss: 1.0205 - val_accuracy: 0.4963\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 1.1659 - accuracy: 0.4562 - val_loss: 1.0506 - val_accuracy: 0.5037\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 1.1692 - accuracy: 0.4600 - val_loss: 1.0071 - val_accuracy: 0.5185\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 1.1444 - accuracy: 0.4525 - val_loss: 0.9879 - val_accuracy: 0.5630\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.1007 - accuracy: 0.4916 - val_loss: 0.9921 - val_accuracy: 0.5481\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.1245 - accuracy: 0.4860 - val_loss: 1.0133 - val_accuracy: 0.4370\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.1062 - accuracy: 0.4823 - val_loss: 0.9878 - val_accuracy: 0.4889\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.0779 - accuracy: 0.5177 - val_loss: 1.0879 - val_accuracy: 0.5407\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.0721 - accuracy: 0.4898 - val_loss: 0.9236 - val_accuracy: 0.5556\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.0498 - accuracy: 0.5065 - val_loss: 0.9278 - val_accuracy: 0.5556\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.0007 - accuracy: 0.5382 - val_loss: 0.8862 - val_accuracy: 0.5185\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.0205 - accuracy: 0.5438 - val_loss: 0.9860 - val_accuracy: 0.5037\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.9777 - accuracy: 0.5345 - val_loss: 0.9231 - val_accuracy: 0.5185\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.9908 - accuracy: 0.5326 - val_loss: 0.8900 - val_accuracy: 0.5407\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.9694 - accuracy: 0.5400 - val_loss: 0.9291 - val_accuracy: 0.5704\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.0274 - accuracy: 0.5549 - val_loss: 1.0364 - val_accuracy: 0.5556\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.9574 - accuracy: 0.5326 - val_loss: 0.9848 - val_accuracy: 0.5333\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.9699 - accuracy: 0.5754 - val_loss: 0.8696 - val_accuracy: 0.5704\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.9581 - accuracy: 0.5512 - val_loss: 0.9463 - val_accuracy: 0.5111\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.9500 - accuracy: 0.5326 - val_loss: 0.8139 - val_accuracy: 0.5778\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.9255 - accuracy: 0.5903 - val_loss: 0.8326 - val_accuracy: 0.6074\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.9678 - accuracy: 0.5363 - val_loss: 0.9756 - val_accuracy: 0.5481\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.9541 - accuracy: 0.5661 - val_loss: 1.0028 - val_accuracy: 0.6000\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.9139 - accuracy: 0.5959 - val_loss: 0.8782 - val_accuracy: 0.6074\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.8975 - accuracy: 0.5866 - val_loss: 0.8323 - val_accuracy: 0.6074\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.9013 - accuracy: 0.5847 - val_loss: 0.7950 - val_accuracy: 0.5926\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.8702 - accuracy: 0.5866 - val_loss: 0.7612 - val_accuracy: 0.6519\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.8849 - accuracy: 0.6034 - val_loss: 0.7708 - val_accuracy: 0.6519\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.8856 - accuracy: 0.5903 - val_loss: 0.8165 - val_accuracy: 0.6148\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.9088 - accuracy: 0.5661 - val_loss: 0.9598 - val_accuracy: 0.5704\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.8573 - accuracy: 0.5940 - val_loss: 0.9125 - val_accuracy: 0.5111\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.8698 - accuracy: 0.6089 - val_loss: 0.8721 - val_accuracy: 0.5852\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.8659 - accuracy: 0.6089 - val_loss: 0.8200 - val_accuracy: 0.6444\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.8035 - accuracy: 0.6034 - val_loss: 0.8255 - val_accuracy: 0.6296\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.7853 - accuracy: 0.6536 - val_loss: 0.8350 - val_accuracy: 0.5778\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.8149 - accuracy: 0.6238 - val_loss: 0.8237 - val_accuracy: 0.5778\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.8268 - accuracy: 0.6406 - val_loss: 0.7404 - val_accuracy: 0.6593\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.8524 - accuracy: 0.6164 - val_loss: 0.7699 - val_accuracy: 0.5704\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.8056 - accuracy: 0.6238 - val_loss: 0.7986 - val_accuracy: 0.6074\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.7628 - accuracy: 0.6574 - val_loss: 0.6876 - val_accuracy: 0.6741\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.7681 - accuracy: 0.6425 - val_loss: 0.7343 - val_accuracy: 0.6296\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.7451 - accuracy: 0.6574 - val_loss: 0.7369 - val_accuracy: 0.6148\n"
     ]
    }
   ],
   "source": [
    "smhistory=sm.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K51eTwPjnIGJ",
    "outputId": "82569664-abb9-4322-8290-f724a128949b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18324), started 0:02:26 ago. (Use '!kill 18324' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4eae062097fa5cd3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4eae062097fa5cd3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Config - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LBS8v4sWnIjJ",
    "outputId": "34487bd9-7587-4805-a2e6-9f19e8e9e419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7369 - accuracy: 0.6148\n",
      "Restored model, accuracy: 61.48%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = sm.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration 4 - LSTM_RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 180, 64)           16896     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,440\n",
      "Trainable params: 50,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_LSTM=Sequential()\n",
    "model_LSTM.add(layers.LSTM(64,return_sequences=True,input_shape=(180,1)))\n",
    "model_LSTM.add(layers.LSTM(64))\n",
    "model_LSTM.add(layers.Dense(8,activation='softmax'))\n",
    "print(model_LSTM.summary())\n",
    "model_LSTM.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 23s 305ms/step - loss: 1.5482 - accuracy: 0.3035 - val_loss: 1.3649 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 5s 195ms/step - loss: 1.3753 - accuracy: 0.3464 - val_loss: 1.2642 - val_accuracy: 0.3407\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 1.3113 - accuracy: 0.3594 - val_loss: 1.1756 - val_accuracy: 0.5037\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 5s 203ms/step - loss: 1.3049 - accuracy: 0.4022 - val_loss: 1.1525 - val_accuracy: 0.5185\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 5s 204ms/step - loss: 1.2507 - accuracy: 0.4060 - val_loss: 1.1699 - val_accuracy: 0.5333\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 1.2193 - accuracy: 0.4525 - val_loss: 1.0876 - val_accuracy: 0.4963\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 1.2198 - accuracy: 0.4171 - val_loss: 1.1357 - val_accuracy: 0.4370\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 5s 196ms/step - loss: 1.1949 - accuracy: 0.4469 - val_loss: 1.1124 - val_accuracy: 0.4296\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 5s 196ms/step - loss: 1.1960 - accuracy: 0.4469 - val_loss: 1.0592 - val_accuracy: 0.5481\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 1.1305 - accuracy: 0.4916 - val_loss: 1.2744 - val_accuracy: 0.4296\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 5s 201ms/step - loss: 1.1971 - accuracy: 0.4655 - val_loss: 1.0234 - val_accuracy: 0.5630\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 5s 203ms/step - loss: 1.1264 - accuracy: 0.4823 - val_loss: 1.0105 - val_accuracy: 0.5630\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 5s 196ms/step - loss: 1.1336 - accuracy: 0.4953 - val_loss: 1.0632 - val_accuracy: 0.4815\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 5s 200ms/step - loss: 1.1293 - accuracy: 0.4562 - val_loss: 0.9831 - val_accuracy: 0.5185\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 5s 200ms/step - loss: 1.0760 - accuracy: 0.5196 - val_loss: 1.9688 - val_accuracy: 0.4222\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 1.1717 - accuracy: 0.4786 - val_loss: 0.9799 - val_accuracy: 0.5556\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 6s 204ms/step - loss: 1.0959 - accuracy: 0.5102 - val_loss: 0.9902 - val_accuracy: 0.5630\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 1.1055 - accuracy: 0.5065 - val_loss: 0.9892 - val_accuracy: 0.5037\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 6s 205ms/step - loss: 1.0979 - accuracy: 0.4600 - val_loss: 1.0169 - val_accuracy: 0.5481\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 1.0991 - accuracy: 0.4916 - val_loss: 0.9927 - val_accuracy: 0.5111\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 5s 204ms/step - loss: 1.0874 - accuracy: 0.4972 - val_loss: 1.0033 - val_accuracy: 0.5111\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 5s 202ms/step - loss: 1.0800 - accuracy: 0.5065 - val_loss: 0.9733 - val_accuracy: 0.5111\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 5s 204ms/step - loss: 1.0851 - accuracy: 0.5009 - val_loss: 0.9422 - val_accuracy: 0.5630\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 1.0802 - accuracy: 0.4991 - val_loss: 0.9434 - val_accuracy: 0.5259\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 5s 202ms/step - loss: 1.0854 - accuracy: 0.5047 - val_loss: 0.9570 - val_accuracy: 0.5778\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 5s 203ms/step - loss: 1.0658 - accuracy: 0.5196 - val_loss: 1.0296 - val_accuracy: 0.4741\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 1.1512 - accuracy: 0.4730 - val_loss: 0.9493 - val_accuracy: 0.5333\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 6s 208ms/step - loss: 1.0948 - accuracy: 0.5121 - val_loss: 0.9567 - val_accuracy: 0.5630\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 5s 204ms/step - loss: 1.0565 - accuracy: 0.5214 - val_loss: 0.9493 - val_accuracy: 0.5333\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 1.0651 - accuracy: 0.5065 - val_loss: 0.9629 - val_accuracy: 0.5259\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 6s 205ms/step - loss: 1.0821 - accuracy: 0.4916 - val_loss: 0.9693 - val_accuracy: 0.5630\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 1.0637 - accuracy: 0.5158 - val_loss: 0.9794 - val_accuracy: 0.5556\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 5s 195ms/step - loss: 1.0799 - accuracy: 0.5028 - val_loss: 0.9813 - val_accuracy: 0.5185\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 1.0655 - accuracy: 0.5102 - val_loss: 0.9558 - val_accuracy: 0.5185\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 1.0504 - accuracy: 0.5140 - val_loss: 0.9370 - val_accuracy: 0.5259\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 1.0567 - accuracy: 0.5121 - val_loss: 1.1547 - val_accuracy: 0.4519\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 5s 204ms/step - loss: 1.0442 - accuracy: 0.5289 - val_loss: 0.9414 - val_accuracy: 0.5556\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 5s 196ms/step - loss: 1.0734 - accuracy: 0.5140 - val_loss: 0.9483 - val_accuracy: 0.5111\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 1.0287 - accuracy: 0.5270 - val_loss: 1.0766 - val_accuracy: 0.4667\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 1.0406 - accuracy: 0.5345 - val_loss: 0.9318 - val_accuracy: 0.5630\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 5s 196ms/step - loss: 1.0333 - accuracy: 0.5102 - val_loss: 0.9632 - val_accuracy: 0.5333\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 1.0414 - accuracy: 0.5251 - val_loss: 0.9499 - val_accuracy: 0.5481\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 5s 201ms/step - loss: 1.0178 - accuracy: 0.5345 - val_loss: 1.0475 - val_accuracy: 0.5111\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 5s 190ms/step - loss: 1.0555 - accuracy: 0.5270 - val_loss: 1.1194 - val_accuracy: 0.4519\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 1.0517 - accuracy: 0.5270 - val_loss: 1.1206 - val_accuracy: 0.4296\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 5s 193ms/step - loss: 1.0375 - accuracy: 0.5363 - val_loss: 0.9433 - val_accuracy: 0.5333\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 1.0463 - accuracy: 0.5158 - val_loss: 0.9258 - val_accuracy: 0.5333\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 1.0306 - accuracy: 0.5214 - val_loss: 0.9594 - val_accuracy: 0.5259\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 1.0472 - accuracy: 0.5140 - val_loss: 1.1375 - val_accuracy: 0.4222\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 1.0310 - accuracy: 0.5289 - val_loss: 0.9784 - val_accuracy: 0.5111\n"
     ]
    }
   ],
   "source": [
    "umhistory=model_LSTM.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Config - 4 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 71ms/step - loss: 0.9784 - accuracy: 0.5111\n",
      "Restored model, accuracy: 51.11%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_LSTM.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis and Visualization of all Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18324), started 0:07:19 ago. (Use '!kill 18324' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1bed13b71a398e1d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1bed13b71a398e1d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOQfsKtSS2nu7fsGE+IWtmN",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CNN_SpeechEmotion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
